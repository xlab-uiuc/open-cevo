Issue-ID,Title,Parameter,Issue-URL,Commit-URL,Change type,Param type,Pattern,Note
HBASE-18786,FileNotFoundException should not be silently handled for primary region replicas,hbase.hregion.unassign.for.fnfe,https://issues.apache.org/jira/browse/HBASE-18786,https://github.com/apache/hbase/commit/b27f9b582a858fba66036413936debad27737c3a,hard-coded logic,bool,make feature mandatory,"this is not something that should be parameterized. We either do it or we don't. Otherwise it becomes an obscure setting that could lead to serious conditions if an operator changes it to the non-default value, which we know won't be well tested.For me, FNFE should not happen and if it happens then there must be serious bugs that may cause data loss.That's why I introduce a config, the intention is to disable the feature as we used to always handle it silently..."
HBASE-19999,Remove the SYNC_REPLICATION_ENABLED flag,hbase.replication.sync.enabled,https://issues.apache.org/jira/browse/HBASE-19999,https://github.com/apache/hbase/commit/c7d1085fa27a64621d262aefea825e980e6bc576,hard-coded logic,bool,make feature mandatory,It is a bit strange since we can not guard all the sync replication related code with it. We'd better change its name and only use it within the WAL construction. Now the default case will use SyncReplicationWALProvider.only disable SyncReplicationWALProvider for HMaster or HRegionServer which take system table only.
HBASE-8518,Get rid of hbase.hstore.compaction.complete setting,hbase.hstore.compaction.complete,https://issues.apache.org/jira/browse/HBASE-8518,https://github.com/apache/hbase/commit/a21eb68f9584e69157fed683cc512ee3e8963dfb,hard-coded logic,bool,make feature mandatory,hbase.hstore.compaction.complete is a strange setting that causes the finished compaction to not complete (files are just left in tmp) in HStore. Looks like a flag which allow compacted files to be created but not used. May be someone who wants to see the time /size of compaction without affecting the stores. Does not seem very useful.
SPARK-23366,Improve hot reading path in ReadAheadInputStream,spark.unsafe.sorter.spill.read.ahead.fraction,https://issues.apache.org/jira/browse/SPARK-23366,https://github.com/apache/spark/commit/7539ae59d6c354c95c50528abe9ddff6972e960f,hard-coded logic,bool,make feature mandatory,"Remove `readAheadThresholdInBytes` and instead immediately trigger async read when switching the buffers. It allows to simplify code paths, especially the hot one that then only has to check if there is available data in the active buffer, without worrying if it needs to retrigger async read. It seems to have positive effect on perf."
SPARK-26362,Remove 'spark.driver.allowMultipleContexts' to disallow multiple Spark contexts,spark.driver.allowMultipleContexts,https://issues.apache.org/jira/browse/Spark-26362,https://github.com/apache/spark/commit/9ccae0c9e7d1a0a704e8cd7574ba508419e05e30,hard-coded logic,bool,make feature mandatory,"Multiple SparkContexts are discouraged and it has been warning for last 4 years, see SPARK-4180. It could cause arbitrary and mysterious error cases, see SPARK-2243. Honestly, I didn't even know Spark still allows it, which looks never officially supported, see SPARK-2243."
SPARK-27938,Remove feature flag LEGACY_PASS_PARTITION_BY_AS_OPTIONS,LEGACY_PASS_PARTITION_BY_AS_OP,https://issues.apache.org/jira/browse/Spark-27938,https://github.com/apache/spark/commit/eee3467b1ea674a64a3c70775cfbf2710318993e,hard-coded logic,bool,make feature mandatory,"To make this change less intrusive for a patch release, we added a feature flag `LEGACY_PASS_PARTITION_BY_AS_OPTIONS` with the default to be false. For 3.0, we should just do the correct behavior for DSV1, i.e., always passing partitionBy as options, and remove this legacy feature flag."
SPARK-28699,Cache an indeterminate RDD could lead to incorrect result while stage rerun,SQLConf.get.enableRadixSort,https://issues.apache.org/jira/browse/SPARK-28699,https://github.com/apache/spark/commit/2d9cc42aa83beb5952bb44d3cd0327d4432d385,hard-coded logic,bool,make feature mandatory,"After further investigation, we found that this bug is nothing to do with cache operation. So we focus on the sort + shuffle self and finally found the root cause is about the wrong usage for radix sort."
HBASE-22760,Stop/Resume Snapshot Auto-Cleanup activity with shell command,hbase.master.cleaner.snapshot.disable,https://issues.apache.org/jira/browse/HBASE-22760,https://github.com/apache/hbase/commit/1dcc8ee50cd2120496ec768e09e7f368b6bc26b,hard-coded logic,bool,make feature mandatory,"For any scheduled snapshot backup activity, we would like to disable auto-cleaner for snapshot based on TTL. However, as per HBASE-22648 we have a config to disable snapshot auto-cleaner: hbase.master.cleaner.snapshot.disable, which would take effect only upon HMaster restart just similar to any other hbase-site configs."
CASSANDRA-14108,Improve commit log chain marker updating,commitlog_marker_period_in_ms,https://issues.apache.org/jira/browse/CASSANDRA-14108,https://github.com/apache/cassandra/commit/db788fe860dfd69f06ab97ae35fa67fcf2517b6d,hard-coded value,time,using 100,"Instead of requiring users to configure a deep, dark implementation detail like the commit log chained markers (via commitlog_marker_period_in_ms in the yaml), we decided it is best to eliminate thew configuration and always update the chained markers (when in periodic mode). I've removed the confusing (and confusingly described) yaml property for setting the commitlog_marker_period_in_ms. Instead, I've hardcoded the marker interval to 100ms and it is always applied when a) using periodic mode, and b) not using compression or encryption."
HBASE-19282,Making CellChunkMap the default index,hbase.hregion.compacting.memstore.index,https://issues.apache.org/jira/browse/HBASE-19282,https://github.com/apache/hbase/commit/8d0da1a77f50b730b366c28b5b477141aa83cc55,hard-coded value,index,using orignial default value,In order to avoid additional user settings. If no MSLAB is requested the index is going to be CellArrayMap
HDFS-12412,Change ErasureCodingWorker.stripedReadPool to cached thread pool.,dfs.datanode.ec.reconstruction.stripedread.threads,https://issues.apache.org/jira/browse/HDFS-12412,https://github.com/apache/hadoop/commit/123342cd0759ff88801d4f5ab10987f6e3f344b0,hard-coded value,thread number,using Integer.MAX_VALUE,"The idea to remove the striped read pool and reuse the same reconstruction pool sounds good to me, since given the later and the most often used erasure codec, we can roughly estimate the striped read threads need. We can also simplify the configuration and codes. Less configuration with reasonable defaults would make the brand feature more easier to use. When needed, we can fine-tune and add more later."
HDFS-12775,READ] Fix reporting of Provided volumes,dfs.provided.df.class,https://issues.apache.org/jira/browse/HDFS-12775,https://github.com/apache/hadoop/commit/3b1d30301bcd35bbe525a7e122d3e5acfab92c88,hard-coded value,class implementation,using orignial default value,"The capacity (and dfs used) of a PROVIDED volume on a DN is reported to be equal to the total size of the data (in bytes) mounted from the remote storage. Each volume reports zero available capacity (thus 100% usage). This included changes to ProvidedVolumeImpl, and adding a default ProvidedVolumeDFimplementation and removing the earlier configurable ProvidedVolumeDF interface."
SPARK-25704,Allocate a bit less than Int.MaxValue,spark.storage.memoryMapLimitForTests,https://issues.apache.org/jira/browse/SPARK-25704,https://github.com/apache/spark/commit/43717dee570dc41d71f0b27b8939f6297a029a02,hard-coded value,maxChunkSize,using Integer.MAX_VALUE - 15,"Replicating a block > 2GB currently fails because it tries to allocate a bytebuffer that is just a bit too large, due to a bad default config. MEMORY_MAP_LIMIT_FOR_TESTS defaults to Integer.MAX_VALUE, but unfortunately that is just a tiny bit too big. Workaround: Set to ""spark.storage.memoryMapLimitForTests"" something a bit smaller, eg. 2147483135 (that's Integer.MAX_VALUE - 512, just in case its a bit different on other systems)."
CASSANDRA-13990,Remove obsolete OldNetworkTopologyStrategy,replication_factor_strategies,https://issues.apache.org/jira/browse/CASSANDRA-13990,https://github.com/apache/cassandra/commit/7c5904753f4ede492f1a5a5e68edfe37651a5be6,hard-coded value,class implementation,using orignial default value,RackAwareStrategy was renamed OldNetworkTopologyStrategy back in 0.7 (CASSANDRA-1392) and it's still around.
HBASE-16894,"Create more than 1 split per region, generalize HBASE-12590",hbase.mapreduce.input.autobalance.maxskewratio,https://issues.apache.org/jira/browse/HBASE-16894,https://github.com/apache/hbase/commit/16d483f9003ddee71404f37ce7694003d1a18ac4,program control,ratio,using better feature,"If we want to fix this properly, we should extend the approach in HBASE-12590, and make it so that the client can specify the desired num of mappers, or desired split size, and the TIF generates the splits based on the current region sizes very similar to the algorithm in HBASE-12590, but a more generic way. This also would eliminate the hand tuning of data skew ratio."
HBASE-19616,Review of LogCleaner Class,hbase.oldwals.cleaner.thread.check.interval.msec,https://issues.apache.org/jira/browse/HBASE-19616,https://github.com/apache/hbase/commit/af923225d0a874ecf3c7deddbc0d7bc82184e1d1,program control,interval,using better feature,Using a CountDownLatch allows one or more threads to wait until a set of operations being performed in other threads completes. It will not blindly sleep between checks and it will return immediately after the condition is met. This removes the HBase configuration that controls the sleep interval.
HBASE-21228,Memory leak since AbstractFSWAL caches Thread object and never clean later,REGION_SERVER_HANDLER_COUNT,https://issues.apache.org/jira/browse/HBASE-21228,https://github.com/apache/hbase/commit/86cb8e48ad8aecf52bca1169a98607c76198c70b,program control,thread number,using better feature,"In one of our customer's cluster, we noticed that even though there is no requests, the heap of the RS is almost full and CMS GC was triggered every second. We dumped the heap and then found out there were more than 30 thousands threads with Terminated state. which are all cached in this map above. Everything referenced in these threads were leaked."