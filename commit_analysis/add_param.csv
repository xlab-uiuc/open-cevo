Issue link,Commit link,change mode,Title,param_name
HDFS-11975,https://github.com/apache/hadoop/commit/a53b8b6fdce111b1e35ad0dc563eb53d1c58462f,Add CodeChange,Provide a system-default EC policy.,dfs.namenode.ec.system.default.policy
HDFS-14017,https://github.com/apache/hadoop/commit/a3aab48df0b99f70f6f66474255fe06141894b6e,Add CodeChange,ObserverReadProxyProviderWithIPFailover should work with HA configuration,DFS_CLIENT_FAILOVER_IPFAILOVER_VIRTUAL_ADDRESS
HDFS-11799,https://github.com/apache/hadoop/commit/fda1221c55101d97ac62e1ee4e3ddf9a915d5363,Add CodeChange,Introduce a **CONFIG** to allow setting up write pipeline with fewer nodes than replication factor.,dfs.client.block.write.replace-datanode-on-failure.min-replication
HDFS-11887,https://github.com/apache/hadoop/commit/d6dd557b24201720adec5794737a3c25a5ed6ba2,Add CodeChange,Shared XceiverClient should be closed if there is no open clients to avoid resource leak.,scm.container.client.max.size
HDFS-12802,https://github.com/apache/hadoop/commit/d9006d8a4e34eae78dfa1cf3be50eeb81c2fc11f,Add CodeChange,RBF: Control MountTableResolver cache size,FEDERATION_MOUNT_TABLE_MAX_CACHE_SIZE
HDFS-12978,https://github.com/apache/hadoop/commit/ebe5853a458150b7e42fe7434851bfcbe25e354d,Add CodeChange,Fine-grained locking while consuming journal stream,dfs.ha.tail-edits.max-txns-per-lock
HDFS-13119,https://github.com/apache/hadoop/commit/8896d20b91520053a6bbfb680adb345cd24f4142,Add CodeChange,RBF: Manage unavailable clusters. Contributed by Yiqun Lin.,dfs.federation.router.client.retry.max.attempts dfs.federation.router.client.thread-size
HDFS-13536,https://github.com/apache/hadoop/commit/1804a31515e541b3371925aa895589919b54d443,Add CodeChange,[PROVIDED Storage] HA for InMemoryAliasMap. ,dfs.provided.aliasmap.inmemory.rpc.bind-host
HDFS-13882,https://github.com/apache/hadoop/commit/10185d9a77ce07080588f3c77399a07cd7ccf427,Add CodeChange,Set a maximum delay for retrying locateFollowingBlock.,dfs.client.block.write.locateFollowingBlock.max.delay.ms
HDFS-12904,https://github.com/apache/hadoop/commit/72d8b92ba5bdc5dc0cf434d06d90fb0b1810fec,Add CodeChange, Add DataTransferThrottler to the Datanode transfers.,dfs.datanode.data.transfer.bandwidthPerSec
HDFS-14973,https://github.com/apache/hadoop/commit/b2cc8b6b4a78f31cdd937dc4d1a2255f80c5881,Add CodeChange, More strictly enforce Balancer/Mover/SPS throttling of getBlocks RPCs to NameNodes. ,dfs.namenode.get-blocks.max-qps
HDFS-14651,https://github.com/apache/hadoop/commit/9b6906fe914829f50076c2291dba59d425475d7,Add CodeChange, DeadNodeDetector checks dead node periodically,"dfs.client.deadnode.detection.probe.connection.timeout.ms, dfs.client.deadnode.detection.probe.deadnode.interval.ms, dfs.client.deadnode.detection.rpc.threads, dfs.client.deadnode.detection.probe.deadnode.threads, dfs.client.deadnode.detection.deadnode.queue.max"
HDFS-14649,https://github.com/apache/hadoop/commit/c8bef4d6a6d7d5affd00cff6ea4a2e2ef778050,Add CodeChange, Add suspect probe for DeadNodeDetector. ,"dfs.client.deadnode.detection.suspectnode.queue.max, dfs.client.deadnode.detection.probe.suspectnode.threads, dfs.client.deadnode.detection.probe.suspectnode.interval.ms"
HDFS-14854,https://github.com/apache/hadoop/commit/c93cb6790e0f1c64efd03d859f907a052201089,Add CodeChange, Create improved decommission monitor implementation.,"dfs.namenode.decommission.monitor.class, dfs.namenode.decommission.backoff.monitor.pending.limit, dfs.namenode.decommission.backoff.monitor.pending.blocks.per.lock, DFS.NAMENODE.DECOMMISSION.MAX.CONCURRENT.TRACKED.NODES"
HDFS-2470,https://github.com/apache/hadoop/commit/07e3cf952eac9e47e7bd5e195b0f9fc28c46831,Add CodeChange, NN should automatically set permissions on dfs.namenode.*.dir. ,"dfs.namenode.storage.dir.perm, dfs.journalnode.edits.dir.perm"
HDFS-14795,https://github.com/apache/hadoop/commit/f580a87079bb47bf92d254677745d067b6bc8fd,Add CodeChange, Add Throttler for writing block. ,dfs.datanode.data.write.bandwidthPerSec
HDFS-10480,https://github.com/apache/hadoop/commit/fb68980959f95f0d89e86f91909867724ad01791,Add NewCode,Add an admin command to list currently open files,dfs.namenode.list.openfiles.num.responses
HDFS-10631,https://github.com/apache/hadoop/commit/7cb6bdf09ed361e067ebf234230babd1391a7d4b,Add NewCode,Federation State Store ZooKeeper implementation.,FEDERATION_STORE_ZK_PARENT_PATH
HDFS-10646,https://github.com/apache/hadoop/commit/b3e6bd22e3c02b3e4f50396538f56a1bcb007638,Add NewCode,Federation admin tool.,DFS_ROUTER_STORE_ENABLE DFS_ROUTER_ADMIN_ENABLE
HDFS-10687,https://github.com/apache/hadoop/commit/55da7fd7ebe2f3fa1c1c828dda727fddc75a1b81,Add NewCode,Federation Membership State Store internal API.,dfs.federation.router.cache.ttl dfs.federation.router.store.membership.expiration
HDFS-10899,https://github.com/apache/hadoop/commit/1000a2af04b24c123a3b08168f36b4e90420cab7,Add NewCode,Add functionality to re-encrypt EDEKs.,dfs.namenode.list.reencryption.status.num.responses dfs.namenode.reencrypt.sleep.interval dfs.namenode.reencrypt.batch.size dfs.namenode.reencrypt.batch.size dfs.namenode.reencrypt.throttle.limit.handler.ratio dfs.namenode.reencrypt.edek.threads dfs.namenode.reencrypt.throttle.limit.updater.ratio
HDFS-11789,https://github.com/apache/hadoop/commit/6d116ffad23b470f8e9ca131d8e89cbbbb4378d7,Add NewCode,Maintain Short-Circuit Read Statistics,METRICS_SAMPLING_PERCENTAGE_KEY
HDFS-11826,https://github.com/apache/hadoop/commit/d8c81073320320a019fb3868be4f06f46aebea43,Add NewCode,Federation Namenode Heartbeat.,DFS_ROUTER_HEARTBEAT_ENABLE DFS_ROUTER_HEARTBEAT_INTERVAL_MS DFS_ROUTER_MONITOR_NAMENODE
HDFS-12273,https://github.com/apache/hadoop/commit/81601dac8ec7650bec14700b174910390a92fe1f,Add NewCode,Federation UI,DFS_ROUTER_HTTP_ENABLE DFS_ROUTER_HTTP_ADDRESS_KEY DFS_ROUTER_HTTP_BIND_HOST_KEY DFS_ROUTER_HTTPS_ADDRESS_KEY DFS_ROUTER_HTTPS_BIND_HOST_KEY
HDFS-12291,https://github.com/apache/hadoop/commit/bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923,Add NewCode,Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir.,dfs.storage.policy.satisfier.queue.limit dfs.storage.policy.satisfier.work.multiplier.per.iteration
HDFS-12335,https://github.com/apache/hadoop/commit/bc9e588a19c0aaf518de8dab719362be4a8d6a54,Add NewCode,Federation Metrics.,DFS_ROUTER_METRICS_ENABLE DFS_ROUTER_METRICS_CLASS
HDFS-12591,https://github.com/apache/hadoop/commit/b634053c4daec181511abb314aeef0a8fe851086,Add NewCode,[READ] Implement LevelDBFileRegionFormat.,dfs.provided.aliasmap.leveldb.read.path
HDFS-12665,https://github.com/apache/hadoop/commit/352f994b6484524cdcfcda021046c59905b62f31,Add NewCode,[AliasMap] Create a version of the AliasMap that runs in memory in the Namenode (leveldb).,dfs.provided.aliasmap.inmemory.dnrpc-address dfs.provided.aliasmap.inmemory.leveldb.dir dfs.provided.aliasmap.inmemory.batch-size dfs.provided.aliasmap.inmemory.enabled
HDFS-12934,https://github.com/apache/hadoop/commit/d98a2e6e2383f8b66def346409b0517aa32d298d,Add NewCode,RBF: Federation supports global quota.,DFS_ROUTER_QUOTA_ENABLE DFS_ROUTER_QUOTA_CACHE_UPATE_INTERVAL
HDFS-13022,https://github.com/apache/hadoop/commit/377b31ffa1234889d55c1d15832c87bfcef818ba,Add NewCode,Block Storage: Kubernetes dynamic persistent volume provisioner.,dfs.cblock.kubernetes.dynamic-provisioner.enabled dfs.cblock.kubernetes.cblock-user dfs.cblock.kubernetes.configfile dfs.cblock.iscsi.advertised.ip dfs.cblock.iscsi.advertised.port
HDFS-13042,https://github.com/apache/hadoop/commit/7721fff74494eb7fbbbba7f8bb4b4692d880d301,Add NewCode,RBF: Heartbeat Router State.,dfs.federation.router.heartbeat-state.interval dfs.federation.router.expiration
HDFS-13044,https://github.com/apache/hadoop/commit/dbb9dded33b3cff3b630e98300d30515a9d1eec4,Add NewCode,RBF: Add a safe mode for the Router.,DFS_ROUTER_SAFEMODE_ENABLE DFS_ROUTER_SAFEMODE_EXTENSION DFS_ROUTER_SAFEMODE_EXPIRATION
HDFS-13056,https://github.com/apache/hadoop/commit/7c9cdad6d04c98db5a83e2108219bf6e6c903daf,Add NewCode,Expose file-level composite CRCs in HDFS which are comparable across different instances/layouts.,dfs.checksum.combine.mode
HDFS-13060,https://github.com/apache/hadoop/commit/af015c0b2359be317132e2cf35735429f4f34ea7,Add NewCode,Adding a BlacklistBasedTrustedChannelResolver for Trusted ChannelResolver,dfs.datatransfer.server.fixedBlackList.file dfs.datatransfer.server.variableBlackList.enable dfs.datatransfer.server.variableBlackList.file dfs.datatransfer.server.variableBlackList.cache.secs dfs.datatransfer.client.fixedBlackList.file dfs.datatransfer.client.variableBlackList.enable dfs.datatransfer.client.variableBlackList.file dfs.datatransfer.client.variableBlackList.cache.secs
HDFS-13077,https://github.com/apache/hadoop/commit/d3de4fb2a084cbadab8ef91f11aa7732d3b0f308,Add NewCode,[SPS]: Fix review comments of external storage policy satisfier.,dfs.storage.policy.satisfier.max.outstanding.paths dfs.storage.policy.satisfier.address dfs.storage.policy.satisfier.keytab.file dfs.storage.policy.satisfier.kerberos.principal
HDFS-13166,https://github.com/apache/hadoop/commit/75ccc1396b677777cdc0d4992a4af3911f9f88c2,Add NewCode,Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls.,dfs.storage.policy.satisfier.datanode.cache.refresh.interval.ms
HDFS-13224,https://github.com/apache/hadoop/commit/e71bc00a471422ddb26dd54e706f09f0fe09925c,Add NewCode,RBF: Resolvers to support mount points across multiple subclusters.,MIN_UPDATE_PERIOD_KEY
HDFS-13291,https://github.com/apache/hadoop/commit/cfc3a1c8f06fba4f4bd5ffe8bb2a6944d066948e,Add NewCode,RBF: Implement available space based OrderResolver.,BALANCER_PREFERENCE_KEY
HDFS-13347,https://github.com/apache/hadoop/commit/a71656c1c1bf6c680f1382a76ddcac870061f320,Add NewCode,RBF: Cache datanode reports,DN_REPORT_TIME_OUT DN_REPORT_CACHE_EXPIRE
HDFS-13358,https://github.com/apache/hadoop/commit/75f8b6ccfa6160e695ce8f7ad13c6e3624e9e7aa,Add NewCode,RBF: Support for Delegation Token (RPC),dfs.federation.router.secret.manager.class
HDFS-13443,https://github.com/apache/hadoop/commit/8f6f9d9c8398567064c9369f48213db63f45538c,Add NewCode,RBF: Update mount table cache immediately after changing (add/update/remove) mount table entries.,dfs.federation.router.mount-table.cache.update dfs.federation.router.mount-table.cache.update.timeout dfs.federation.router.mount.table.cache.update.client.max.time
HDFS-13547,https://github.com/apache/hadoop/commit/1b0d4f4606adc78a5e43a924634d3d8506db26fa,Add NewCode,Add ingress port based sasl resolver.,ingress.port.sasl.configured.ports
HDFS-13566,https://github.com/apache/hadoop/commit/635786a511344b53b1d3f25c2f29ab5298f6ac74,Add NewCode,Add **CONFIG**urable additional RPC listener to NameNode.,dfs.namenode.rpc-address.auxiliary-ports
HDFS-13607,https://github.com/apache/hadoop/commit/c81ac2ff0220b180cd6cbbf18221290c3783bfd5,Add NewCode,Enhance JournalNode with an in-memory cache of recent edit transactions,dfs.journalnode.edit-cache-size.bytes
HDFS-13609,https://github.com/apache/hadoop/commit/00e99c65943e64fd696ec715cf21e851b93115f1,Add NewCode,NameNode-side changes to support tailing edits via RPC,dfs.ha.tail-edits.qjm.rpc.max-txns dfs.ha.tail-edits.in-progress
HDFS-13617,https://github.com/apache/hadoop/commit/024c87291cb4cc67282fe5645fb827427cc581c6,Add NewCode,Allow wrapping NN QOP into token in encrypted message.,dfs.namenode.send.qop.enabled
HDFS-13699,https://github.com/apache/hadoop/commit/626fec652b9f3dae10c9af78fd220b1240f19fc7,Add NewCode,Add DFSClient sending handshake token to DataNode and allow DataNode overwrite downstream QOP.,dfs.encrypt.data.overwrite.downstream.new.qop
HDFS-13768,https://github.com/apache/hadoop/commit/5689355783de005ebc604f4403dc5129a286bfca,Add NewCode,Adding replicas to volume map makes DataNode start slowly,dfs.datanode.volumes.replica-add.threadpool.size
HDFS-14118,https://github.com/apache/hadoop/commit/f7a27cdee4e6829ebea4ea965e549a27acbf4310,Add NewCode,Support using DNS to resolve nameservices to IP addresses,dfs.client.failover.resolver.impl dfs.client.failover.resolve-needed
HDFS-14211,https://github.com/apache/hadoop/commit/55b3a718e95e62cdd01789050376b36d8e6a0f20,Add NewCode,"[Consistent Observer Reads] Allow for configurable ""always msync"" mode",observer.auto-msync-period
HDFS-14234,https://github.com/apache/hadoop/commit/101d5b5f865f94e4772051ea8ce4ee0f92ddedca,Add NewCode,Limit WebHDFS to specifc user host directory triples,dfs.datanode.httpserver.filter.handlers
HDFS-14316,https://github.com/apache/hadoop/commit/6c42d4050461ab71c88f123569649793dc53aebd,Add NewCode,RBF: Support unavailable subclusters for mount points with multiple destinations,dfs.federation.router.client.mount-status.time-out dfs.federation.router.connect.max.retries.on.timeouts dfs.federation.router.connect.timeout
HDFS-14327,https://github.com/apache/hadoop/commit/7b5b783f66f32012c00bef7593851392dd8cf2d5,Add NewCode,Using FQDN instead of IP to access servers with DNS resolving.,dfs.client.failover.resolver.useFQDN
HDFS-14355,https://github.com/apache/hadoop/commit/35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a,Add NewCode,Implement HDFS cache on SCM by using pure java mapped byte buffer,dfs.datanode.cache.loader.class dfs.datanode.cache.pmem.dirs dfs.datanode.cache.pmem.capacity
HDFS-14403,https://github.com/apache/hadoop/commit/129576f628d370def74e56112aba3a93e97bbf70,Add NewCode,Cost-based extension to the RPC Fair Call Queue.,cost-provider.impl
HDFS-14537,https://github.com/apache/hadoop/commit/6f2c871b05b97ea0e18f3c431af8b0d606f88561,Add NewCode,RBF: Support for Kerberos authentication.,dfs.federation.router.keytab.file dfs.federation.router.kerberos.principal dfs.federation.router.kerberos.principal.hostname dfs.federation.router.kerberos.internal.spnego.principal
HDFS-12594,https://github.com/apache/hadoop/commit/b1c7654ee40b372ed777525a42981c7cf55b5c72,Add NewCode,snapshotDiff fails if the report exceeds the RPC response limit,dfs.namenode.snapshotdiff.listing.limit
HDFS-13173,https://github.com/apache/hadoop/commit/ba82e5c488ca0081534c1e40810b3f9e7da9eaad,Add NewCode,Replace ArrayList with DirectoryDiffList,dfs.namenode.snapshot.skiplist.interval dfs.namenode.snapshot.skiplist.max.levels
HDFS-13283,https://github.com/apache/hadoop/commit/fc074a359c44e84dd9612be2bd772763f943eb04,Add NewCode,Percentage based Reserved Space Calculation for DataNode,dfs.datanode.du.reserved.calculator dfs.datanode.du.reserved.pct
HDFS-14593,https://github.com/apache/hadoop/commit/64d4abf489a0267a265591026f8e6c84bc78591,Add NewCode, RBF: Implement deletion feature for expired records in State Store. ,"FEDERATION.STORE.MEMBERSHIP.EXPIRATION.DELETION.MS, FEDERATION.STORE.ROUTER.EXPIRATION.DELETION.MS"
HDFS-14617,https://github.com/apache/hadoop/commit/b67812ea2111fa11bdd76096b923c93e1bdf292,Add NewCode,Improve fsimage load time by writing sub-sections to the fsimage index (#1028).,"dfs.image.parallel.load, dfs.image.parallel.target.sections, dfs.image.parallel.inode.threshold, dfs.image.parallel.threads"
HDFS-13843,https://github.com/apache/hadoop/commit/c3abfcefdd256650b2a45ae2aac53c4a22721a4,Add NewCode, RBF: Add optional **PARAMETER** -d for detailed listing of mount points. ,-d (command line option)
HDFS-14856,https://github.com/apache/hadoop/commit/fabd41fa480303f86bfe7b6ae0277bc0b6015f8,Add NewCode,Fetch file ACLs while mounting external store. (#1478),dfs.provided.acls.import.enabled
HDFS-14648,https://github.com/apache/hadoop/commit/b3119b9ab60a19d624db476c4e1c53410870c7a,Add NewCode, Implement DeadNodeDetector basic model. ,dfs.client.deadnode.detection.enabled
HDFS-15028,https://github.com/apache/hadoop/commit/11cd5b6e39adbf159891852f3482aebdde5459f,Add NewCode, Keep the capacity of volume and reduce a system call.,dfs.datanode.fixed.volume.size
HDFS-14983,https://github.com/apache/hadoop/commit/93bb368094e48e752c0732d979fbcd24e432bfc,Add NewCode, RBF: Add dfsrouteradmin -refreshSuperUserGroupsConfiguration command option. ,-refreshSuperUserGroupsConfiguration
HDFS-14824,https://github.com/apache/hadoop/commit/477505ccfc480f2605a7b65de95ea6f6ff5ce09,Add NewCode,[Dynamometer] Dynamometer in org.apache.hadoop.tools does not output the benchmark results. (#1685),"auditreplay.output-path, auditreplay.input-path"
HDFS-13783,https://github.com/apache/hadoop/commit/1f26cc8705b5af12eefedda019e7ab5c261d9bf,Add NewCode, Add an **OPTION** to the Balancer to make it run as a long-running service. ,"-asService (command line option), dfs.balancer.service.interval, dfs.balancer.service.retries.on.exception"
HDFS-14882,https://github.com/apache/hadoop/commit/c892a879ddce3abfd51c8609c81148bf6e4f9da,Add NewCode, Consider DataNode load when #getBlockLocation.,"dfs.namenode.read.considerLoad, dfs.namenode.redundancy.considerLoad"
HDFS-14370,https://github.com/apache/hadoop/commit/827dbb11e24be294b40088a8aa46086ba8ca4ba,Add NewCode, Add exponential backoff to the edit log tailer to avoid spinning on empty edit tail requests. ,"dfs.ha.tail-edits.period.backoff-max (new), dfs.ha.tail-edits.period (mdf)"
HBASE-18226,https://github.com/apache/hbase/commit/83be50c2ab01b428df3b0496215fda8d66ae1bd6,add code change,Disable reverse DNS lookup at HMaster and use the hostname provided by RegionServer,hbase.regionserver.hostname.disable.master.reversedns
HBASE-18870,https://github.com/apache/hbase/commit/6712f8f632e6ece032ee45f679db9a42a69f805f,add code change,Hbase Backup should set the details to MR job name,mapreduce.job.name
HBASE-19542,https://github.com/apache/hbase/commit/c811d7f9655a1d424c8d4aeeaf4ef6fdb9d782b6,add code change,fix TestSafemodeBringsDownMaster,hbase.wal.async.wait.on.shutdown.seconds
HBASE-19486,https://github.com/apache/hbase/commit/5a1c36f70ac52e6f4e85f11ea0602d46b4861ac0,add code change,Periodically ensure records are not buffered too long by BufferedMutator,hbase.client.write.buffer.periodicflush.timeout.ms hbase.client.write.buffer.periodicflush.timertick.ms
HBASE-19078,https://github.com/apache/hbase/commit/b4a1dbf7685b9625419297589c4e849207eaf115,add code change,Add a remote peer cluster wal directory **CONFIG** for synchronous replication,remoteWALDir
HBASE-19441,https://github.com/apache/hbase/commit/91075276e7638f64e3e213358edd37198f540e1b,add code change,Implement retry logic around starting exclusive backup operation,hbase.backup.exclusive.op.timeout.seconds
HBASE-21247,https://github.com/apache/hbase/commit/0789f544547505fd457a3a75cf66241dfe1243c0,add code change,Allow WAL Provider to be specified by **CONFIGUR**ation without explicit enum in Providers,hbase.wal.regiongrouping.delegate.provider.class hbase.wal.provider.class hbase.wal.meta_provider.class
HBASE-21626,https://github.com/apache/hbase/commit/e69ab24552babaec934b82b71e1b40a857d7c3e9,add code change,log the regions blocking WAL from being archived,hbase.regionserver.wal.too.old.sec
HBASE-21715,https://github.com/apache/hbase/commit/d4085d11bc2ff1c0b329f603052e94d35a7e2ad0,add code change,Do not throw UnsupportedOperationException in ProcedureFuture.get,hbase.client.procedure.future.get.timeout.msec
HBASE-21806,https://github.com/apache/hbase/commit/c90e9ff5efe26427cb489e455a29f05e7efd0e1b,add code change,add an option to roll WAL on very slow syncs,hbase.regionserver.hlog.roll.on.sync.ms
HBASE-18023,https://github.com/apache/hbase/commit/0e8e176ebd3bd17d969d17ce2b0aa3dafb93fa22,add code change,Log multi-* requests for more than threshold number of rows,hbase.rpc.rows.warning.threshold
HBASE-18090,https://github.com/apache/hbase/commit/4aadc5d322884310ce6ef49fb0031bfbd2a096b9,add code change,Improve TableSnapshotInputFormat to allow more multiple mappers per region,hbase.mapreduce.split.algorithm hbase.mapreduce.splits.per.region
HBASE-18108,https://github.com/apache/hbase/commit/023d4f1ae8081da3cb9ff54e6b2e545799704ce7,add code change,Procedure WALs are archived but not cleaned; fixThe archived Procedure WALs are moved to <hbase_root>/oldWALs/masterProcedureWALsdirectory. ,hbase.master.logcleaner.ttl
HBASE-19344,https://github.com/apache/hbase/commit/49a9fe48830cb0ef0ae9eef2de305420c08d09ab,add code change,improve asyncWAL by using Independent thread for netty #IO in FanOutOneBlockAsyncDFSOutput,hbase.wal.async.use-shared-event-loop
HBASE-19358,https://github.com/apache/hbase/commit/f6f57d38f750c34e2353f605f815c019c8ba3f88,add code change,Improve the stability of splitting log when do fail over,hbase.split.writer.creation.bounded
HBASE-19163,https://github.com/apache/hbase/commit/428e5672e77d6dea9cfdafb5a3052415b9926d12,add code change,Maximum lock count exceeded from region server's batch processing,hbase.regionserver.minibatch.size
HBASE-16060,https://github.com/apache/hbase/commit/67b69fb2c70d3a56ac45f59d57b7f2778094a566,add code change,1.x clients cannot access table state talking to 2.0 cluster,hbase.mirror.table.state.to.zookeeper
HBASE-20370,https://github.com/apache/hbase/commit/d91784e6665c61aef96f4307a847aa197bd25587,add code change,Also remove the wal file in remote cluster when we finish replicating a file,replication.source.sync.sleepforretries replication.source.sync.maxretriesmultiplier
HBASE-20579,https://github.com/apache/hbase/commit/c9f8c3436f6e38b5c7807677c5c3e7fc3e19e071,add code change,Improve snapshot manifest copy in ExportSnapshot,snapshot.export.copy.references.threads
HBASE-20193,https://github.com/apache/hbase/commit/66ad9fdef8e8bff3ed2b77cd8865f724b345bd18,add code change,Basic Replication Web UI,replication.source.getEntries.timeout
HBASE-21098,https://github.com/apache/hbase/commit/5c1b325b510976fe2955593d95690ba507c32e03,add code change,Improve Snapshot Performance with Temporary Snapshot Directory when rootDir on S3,hbase.snapshot.working.dir
HBASE-21227,https://github.com/apache/hbase/commit/d7e08317d2f214e4cca7b67578aba0ed7a567d54,add code change,Implement exponential retrying backoff for Assign/UnassignRegionHandler introduced in HBASE-21217,jitter
HBASE-21325,https://github.com/apache/hbase/commit/c0b994b0c6dcf7b8f6bf9b44491c0a312953c014,add code change,Force to terminate regionserver when abort hang in somewhere,hbase.regionserver.abort.timeout
HBASE-21034,https://github.com/apache/hbase/commit/5ded2944199f27440a46df6f200ff2a31c1b8728,add code change,Add new throttle type: read/write capacity,hbase.quota.read.capacity.unit hbase.quota.write.capacity.unit
HBASE-21754,https://github.com/apache/hbase/commit/b5619a2a26a41c423d6c7af1f1feaa990b63c58c,add code change,ReportRegionStateTransitionRequest should be executed in priority executor,hbase.master.meta.transition.handler.count
HBASE-22005,https://github.com/apache/hbase/commit/35b818606ffb4e67cf9acf3b55af4ea9e3ce8c32,add code change,Use ByteBuff's refcnt to track the life cycle of data block,byteBuffAllocator
HBASE-21871,https://github.com/apache/hbase/commit/177d43d8db8ee90273db1d7c317725f0792a4cd0,add code change,Added support to specify a peer table name in VerifyReplication tool,verifyrep.peerTableName
HBASE-22001,https://github.com/apache/hbase/commit/10ca598004ae7db38945145b232a1c809e4ef6b1,add code change,Polish the Admin interface,hbase.client.sync.wait.timeout.msec
HBASE-21810,https://github.com/apache/hbase/commit/a54f0bfb8f9a0b7d6ec4e4585cd30b9e674bfde8,add code change,bulkload support set hfile compression on client,hbase.mapreduce.hfileoutputformat.compression
HBASE-22057,https://github.com/apache/hbase/commit/59406c44e3ac1c046d0c467d452fca80c848d93a,add code change,Impose upper-bound on size of ZK ops sent in a single multi(),zookeeper.multi.max.size
HBASE-22193,https://github.com/apache/hbase/commit/942f8c45cd1a1e0a8956fc10b811dd2add510645,add code change,Add backoff when region failed open too many times,hbase.assignment.retry.immediately.maximum.attempts
HBASE-22292,https://github.com/apache/hbase/commit/6855143ba90ada2e731ff82dfcc5d250e1f8329a,add code change,PreemptiveFastFailInterceptor clean repeatedFailuresMap issue,hbase.client.failure.map.cleanup.interval
HBASE-22810,https://github.com/apache/hbase/commit/8ffc45ab8b9b658d12ae09aec558654339a6bd8,add code change,Initialize an separate ThreadPoolExecutor for taking/rest……oring snapshot (#486),hbase.master.executor.snapshot.threads
HBASE-18137,https://github.com/apache/hbase/commit/384e308e9f2387422e76ceb1432d6b2b85a973cf,add code change,Replication gets stuck for empty WALs,replication.source.eof.autorecovery
HBASE-18161,https://github.com/apache/hbase/commit/293cb87d52d6ccc98f0d03387f9dc07dc4522042,add new code,Incremental Load support for Multiple-Table HFileOutputFormat,hbase.mapreduce.use.multi.table.hfileoutputformat
HBASE-18843,https://github.com/apache/hbase/commit/a6c9d371df6243458ef2db17bcfea9af890076b8,add new code,Add DistCp support to incremental backup with bulk loading,num.levels.preserve
HBASE-16417,https://github.com/apache/hbase/commit/17e7aff37e6b69cae0fb6d15ebeb2037d1ca6acc,add new code,In-memory MemStore Policy for Flattening and Compactions,hbase.hregion.compacting.memstore.adaptive.compaction.threshold hbase.hregion.compacting.memstore.adaptive.compaction.probability
HBASE-19144,https://github.com/apache/hbase/commit/125f3eace9b35e7947721bba5175ca5dc48921e8#,add new code,[RSgroups] Retry assignments in FAILED_OPEN state when servers (re)join the cluster,hbase.rsgroup.reassign.wait
HBASE-19285,https://github.com/apache/hbase/commit/835d15bf9779698bd0b269c2008a496be79090d2,add new code,"Implements table-level latency histogramsFor a egionserver's view of a table (the regionsthat belong to a table hosted on a regionserver),this change tracks the latencies of operations thataffect the regions for this table.Tracking at the per-table level avoids the memory bloatand performance impact that accompanied the previousper-region latency metrics while still providing importantdetails for operators to consume",hbase.regionserver.enable.table.latencies
HBASE-19492,https://github.com/apache/hbase/commit/03e79b79949a63f7320b4c51fecca40f93659bd9,add new code,Add EXCLUDE_NAMESPACE and EXCLUDE_TABLECFS support to replication peer **CONFIG**,exclude_table_cfs exclude_namespaces
HBASE-19216,https://github.com/apache/hbase/commit/f17198ff199830cba4d888b68720f393c376d3ee,add new code,Implement a general framework to execute remote procedure on RS,hbase.regionserver.executor.refresh.peer.threads
HBASE-19494,https://github.com/apache/hbase/commit/32f6fd41c274a955338b7c43ab80309b9adbba0d,add new code,Create simple WALKey filter that can be plugged in on the Replication SinkImplement new WALEntrySinkFilter (as opposed to WALEntryFilter) andspecify the implmentation (with a no-param constructor) in **CONFIG**using property hbase.replication.sink.walentrysinkfilter,hbase.replication.sink.walentrysinkfilter
HBASE-19957,https://github.com/apache/hbase/commit/39dd81a7c69763475e5a72f6c84e0f450fd957e5,add new code,General framework to transit sync replication state,hbase.replication.sync.enabled
HBASE-19506,https://github.com/apache/hbase/commit/92d04d57516391376d34aaca6307e5906ffa4ae8,add new code,"The CellChunkMap index chunks are usually small, so in order to prevent memory underutilization, HBASE-19506 presents small chunks preallocated in a small pool",hbase.hregion.memstore.mslab.indexchunksize
HBASE-17825,https://github.com/apache/hbase/commit/6cfa208add6ea424e17cae00114ebd3e7d7967f1,add new code,Backup further optimizations,wal.multi.tables.support
HBASE-18133,https://github.com/apache/hbase/commit/bdedcc5631fa9c8c400d4daa01b8a1947d4a12dd,add new code,Decrease quota reaction latency by HBase,hbase.regionserver.quotas.region.size.reporting.chore.period hbase.regionserver.quotas.region.size.reporting.chore.delay hbase.regionserver.quotas.region.size.reporting.chore.timeunit
HBASE-19973,https://github.com/apache/hbase/commit/183b8d0581f82e56e928ca7153ab50558e57045d,add new code,Implement a procedure to replay sync replication wal for standby cluster,hbase.regionserver.executor.replay.sync.replication.wal.threads
HBASE-20050,https://github.com/apache/hbase/commit/99d3edfc82d89d6da23008f3ab0a203317cec6f2,add new code,Reimplement updateReplicationPositions logic in serial replication based on the newly introduced replication storage layer,zookeeper.znode.replication.regions
HBASE-20115,https://github.com/apache/hbase/commit/b7b86839250bf9b295ebc1948826f43a88736d6c,add new code,Reimplement serial replication based on the new replication storage layer,hbase.serial.replication.waiting.ms
HBASE-20117,https://github.com/apache/hbase/commit/b7308ee01c653051db4060ba28dadb5bcc74b7de,add new code,Cleanup the unused replication barriers in meta table,hbase.master.cleaner.replication.barrier.interval
HBASE-20159,https://github.com/apache/hbase/commit/061a31fad1654d9ded96d118e04c14860413fa25,add new code,Support using separate ZK quorums for client,hbase.client.zookeeper.quorum hbase.client.zookeeper.property.clientPort hbase.client.zookeeper.observer.mode
HBASE-18309,https://github.com/apache/hbase/commit/2442cbb6ab5b9f1729b74361dd2bbb066d5910bd,add new code,Support multi threads in CleanerChore,hbase.oldwals.cleaner.thread.size hbase.cleaner.scan.dir.concurrent.size
HBASE-20424,https://github.com/apache/hbase/commit/f67763ffa00ddb3115598dd0047783a8c4d27462,add new code,Allow writing WAL to local and remote cluster concurrently,hbase.wal.sync.impl
HBASE-20636,https://github.com/apache/hbase/commit/3de02d57f632d5c2cb2027cca3bd0333210f5619,add new code,Introduce two bloom filter type : ROWPREFIX and ROWPREFIX_DELIMITED,hbase.hfileoutputformat.families.bloomparam
HBASE-19722,https://github.com/apache/hbase/commit/78e7dd6537801534d02a8bff567e361759b7c5db,add new code,Meta query statistics metrics source,hbase.util.default.lossycounting.errorrate
HBASE-20569,https://github.com/apache/hbase/commit/44ca13fe07dc5050a2bc98ccd3f65953f06aaef8,add new code,NPE in RecoverStandbyProcedure.execute,zookeeper.znode.sync.replication.replaywal.workers
HBASE-20740,https://github.com/apache/hbase/commit/98245ca6e4b6b8cffe22534f32e825c912de2ed3,add new code,StochasticLoadBalancer should consider CoprocessorService request factor when computing cost,hbase.master.balancer.stochastic.cpRequestCost
HBASE-20649,https://github.com/apache/hbase/commit/ba5d1c1f28301adc99019d9d6c4a04fac98ae511,add new code,Validate HFiles do not have PREFIX_TREE DataBlockEncoding,hfilevalidator.numthreads
HBASE-20886,https://github.com/apache/hbase/commit/a8e184dc77470bdf9d62e19c5d36bc1de7cf4c6d,add new code,[Auth] Support keytab login in hbase client,hbase.client.keytab.file hbase.client.keytab.principal
HBASE-20965,https://github.com/apache/hbase/commit/e2fcde2d6f8f57cc28524a855e49c2d65e40b4ba,add new code,Separate region server report requests to new handlers,hbase.regionserver.report.handler.count hbase.master.rpc.scheduler.factory.class hbase.master.server.report.handler.count
HBASE-21072,https://github.com/apache/hbase/commit/86b35b26870be3a04304a4483c08fcf7c50d55f5,add new code,Block out HBCK1 in hbase2Write the hbase-1.x hbck1 lock file to block out hbck1 instances writingstate to an hbase-2.x cluster (could do damage).Set hbase.write.hbck1.lock.file to 0 to disable this writing.,hbase.write.hbck1.lock.file
HBASE-21073,https://github.com/apache/hbase/commit/bc7628a8c34994529011206ee889fb616525ec80,add new code,"Redo concept of maintenance modeInstead of being an ephemeral state set by hbck, maintenance mode is nowan explicit toggle set by either **CONFIG**uration property or environmentvariable. In maintenance mode, master will host system tables and notassign any user-space tables to RSs. This gives operators the ability toaffect repairs to meta table with fewer moving parts.",hbase.master.maintenance_mode
HBASE-19144,https://github.com/apache/hbase/commit/125f3eace9b35e7947721bba5175ca5dc48921e8,add new code,Retry assignments in FAILED_OPEN state when servers (re)join the cluster,hbase.rsgroup.reassign.wait
HBASE-21659,https://github.com/apache/hbase/commit/ec948f5d90fdaf51da7a7a0f7d9013a0c366492e,add new code,Avoid to load duplicate coprocessors in system config and table descriptor,hbase.skip.load.duplicate.table.coprocessor
HBASE-21159,https://github.com/apache/hbase/commit/77db1fae090bc20de62d8a86e9816c69dfb97b7a,add new code,Add shell command to switch throttle on or off,zookeeper.znode.quota.rpc.throttle
HBASE-21588,https://github.com/apache/hbase/commit/281d6429e55149cc4c05430dcc1d1dc136d8b245,add new code,Procedure v2 wal splitting implementation,hbase.split.wal.zk.coordinated
HBASE-21661,https://github.com/apache/hbase/commit/f053003ce7e8d9c86b2ff762b646d69e5e04cfe2,add new code,Provide Thrift2 implementation of Table/Admin,hbase.thrift.client.scanner.caching hbase.thrift.server.name hbase.thrift.server.por hbase.thrift.client.builder.class
HBASE-21867,https://github.com/apache/hbase/commit/72df52283b6c1b60252f6d78ade32a23a59197d5,add new code,Support multi-threads in HFileArchiver,hbase.hfilearchiver.thread.pool.max
HBASE-21926,https://github.com/apache/hbase/commit/6cd78e899fd37393eaa9f142facbee2d9a052dba,add new code,Profiler servlet,async.profiler.home
HBASE-15560,https://github.com/apache/hbase/commit/8ec93ea193f6765fd2639ce851ef8cac7df3f555,add new code,W-TinyLFU based BlockCache,hfile.block.cache.policy
HBASE-22301,https://github.com/apache/hbase/commit/47b4ab7b9732b790b2b471c489f670093e64ad2c,add new code,Consider rolling the WAL if the HDFS write pipeline is slow,hbase.regionserver.wal.slowsync.roll.threshold hbase.regionserver.wal.slowsync.roll.interval.ms
HBASE-22408,https://github.com/apache/hbase/commit/ada772a1d31b2569f349d5bea385c77ea8a40d38,add new code,add a metric for regions OPEN on non-live servers,hbase.assignment.dead.region.metric.chore.interval.msec
HBASE-21995,https://github.com/apache/hbase/commit/c1e5350be794180ce43bdc420b880f21160197d7,add new code,Add a coprocessor to set HDFS ACL for hbase granted user,hbase.user.scan.snapshot.enable hbase.user.scan.snapshot.thread.number
HBASE-18010,https://github.com/apache/hbase/commit/8ac4308411df0528a3ef5a3aae0297154940cd9d,add new code,Connect CellChunkMap to be used for flattening in CompactingMemStore,hbase.hregion.compacting.memstore.index
HBASE-19389,https://github.com/apache/hbase/commit/4f54a66782e1621437a4c8eeea59aec37efa08c4,add new code,Limit concurrency of put with dense (hundreds) columns to prevent write handler exhausted,hbase.region.store.parallel.put.print.threshold hbase.region.store.parallel.put.limit hbase.region.store.parallel.prepare.put.multiplierhbase.region.store.parallel.put.limit.min.column.count
HBASE-22648,https://github.com/apache/hbase/commit/9615c644f595b03cabd18bb0f1bf865ddf5aeb3,add new code,Snapshot TTL (#371),hbase.master.snapshot.ttl hbase.master.cleaner.snapshot.interval
HBASE-22618,https://github.com/apache/hbase/commit/836f26976e1ad8b35d778c563067ed0614c026e,add new code,added the possibility to load custom cost functions,hbase.master.balancer.stochastic.additionalCostFunctions
HBASE-23092,https://github.com/apache/hbase/commit/7ee6d59ef84ee2bdf4425b70ee6fd6ea8954a56,add new code,Make the RM tooling in dev-tools/create-release generic (#……671)Make the scripts generic. Adds an **OPTION** that allows you specify'project'. Defaults to 'hbase' for core. Pass 'hbase-thirdparty'or 'hbase-operator-tools' etc.This commit includes a bunch of bugfixes and miscellaneousthat came of trying to use the scripts making RCs.,project
HBASE-22874,https://github.com/apache/hbase/commit/5aa8d3a20b6e540f4ac361e70690d57e579ea06,add new code,Define a public API for Canary checking and a non-public ……tool implementationCloses #580* Canary is now an IA.Public interface* CanaryTool is now the implementation,hbase.canary.regionserver_all_regions hbase.canary.region.write.sniffing hbase.canary.region.write.table.timeout hbase.canary.region.write.table.name hbase.canary.region.read.table.timeout hbase.canary.zookeeper.permitted.failures hbase.canary.use.regex hbase.canary.timeout hbase.canary.fail.on.error
HBASE-23017,https://github.com/apache/hbase/commit/16da123df45af712f604cff32897d6c1166b86b,add new code,Verify the file integrity in persistent IOEngine,hbase.bucketcache.persistent.file.integrity.check.algorithm
HBASE-23083,https://github.com/apache/hbase/commit/1aee5f0552c93a1e27820b9468771f838a0712c,add new code,Collect Executor status info periodically and report to (#……664)metrics system,hbase.executors.status.collect.enabled
HBASE-22460,https://github.com/apache/hbase/commit/14dcf1d0c6fa6ed4fe95070b0de440c08366855,add new code,: Reopen regions with very high Store Ref Counts (#600),hbase.regions.recovery.store.file.ref.count hbase.master.regions.recovery.check.interval
HBASE-23073,https://github.com/apache/hbase/commit/42d535a57a75b58f585b48df9af9c966e6c7e46,add new code,Add an optional costFunction to balance regions according…… to a capacity rule (#677),hbase.master.balancer.heterogeneousRegionCountRulesFile hbase.master.balancer.heterogeneousRegionCountDefault hbase.master.balancer.stochastic.heterogeneousRegionCountCost
HBASE-23259,https://github.com/apache/hbase/commit/834ccb4bf6c22fc2a8aab172490fba75c7a40f1,add new code,"Populate master address end points in cluster/rs **CONFIG**s (……#807)All the clients need to know the master RPC end points while using masterbased registry for creating cluster connections. This patch amends thetest cluster utility to populate these **CONFIG**s in the base **CONFIG**urationobject used to spin up the cluster.The **CONFIG** key added here (""hbase.master.addrs"") is used in the subsequentpatches for HBASE-18095.",hbase.master.addrs
HBASE-23303,https://github.com/apache/hbase/commit/978546b2f247b29dd63bad55b17fdc2e7a31e55,add new code,Add security headers to REST server/info page (#843),hbase.http.filter.hsts.value hbase.http.filter.csp.value
HBASE-23326,https://github.com/apache/hbase/commit/1b049a2d340636b8f508cc2414db7b731ca9366,add new code,Implement a ProcedureStore which stores procedures in a H……Region (#941),hbase.master.cleaner.interval hbase.procedure.store.region.flush.size hbase.procedure.store.region.flush.per.changes hbase.procedure.store.region.flush.interval.ms hbase.procedure.store.region.compact.min
HBASE-23286,https://github.com/apache/hbase/commit/def9ac7c4586b5414371b4ff3c971de40e6d948,add new code,Improve MTTR: Split WAL to HFile (#820),hbase.wal.split.to.hfile
HBASE-17115,https://github.com/apache/hbase/commit/8b00f9f0b160a3191889aa3a80478525c8faf4b,add new code,"Define UI admins via an ACLThe Hadoop AccessControlList allows us to specify admins of the webUIvia a list of users and/or groups. Admins of the WebUI can mutate thesystem, potentially seeing sensitive data or modifying the system.hbase.security.authentication.spnego.admin.users is a comma-separatedlist of users who are admins.hbase.security.authentication.spnego.admin.groups is a comma-separatedlist of groups whose membership are admins. Either of these**CONFIGUR**ation properties may also contain an asterisk (*) which denotes""any entity"" (e.g user, group).Previously, when a user was denied from some endpoint that wasdesignated for admins, they received an HTTP/401. In this case, it ismore correct to return HTTP/403 as they were correctly authenticated,but they were disallowed from fetching the given resource. This commitincorporates this change.hbase.security.authentication.ui.config.protected also exists for userswho have sensitive information stored in the Hadoop service**CONFIGUR**ation and want to limit access to this endpoint. By default,the Hadoop **CONFIGUR**ation endpoint is not protected and anyauthenticated user can access it.The test is based off of work by Nihal Jain in HBASE-20472.Co-authored-by: Nihal Jain <nihaljain.cs@gmail.com>",HTTP_SPNEGO_AUTHENTICATION_ADMIN_USERS_KEY HTTP_SPNEGO_AUTHENTICATION_ADMIN_GROUPS_KEY hbase.security.authentication.ui.config.protected
HBASE-22749,https://github.com/apache/hbase/commit/b8194b49022e9f550cf2a2fb44cac204b441646,add new code,"Distributed MOB compactions- MOB compaction is now handled in-line with per-region compaction on region  servers- regions with mob data store per-hfile metadata about which mob hfiles are  referenced- admin requested major compaction will also rewrite MOB files; periodic RS  initiated major compaction will not- periodically a chore in the master will initiate a major compaction that  will rewrite MOB values to ensure it happens. controlled by  'hbase.mob.compaction.chore.period'. default is weekly- control how many RS the chore requests major compaction on in parallel  with 'hbase.mob.major.compaction.region.batch.size'. default is as  parallel as possible.- periodic chore in master will scan backing hfiles from regions to get the  set of referenced mob hfiles and archive those that are no longer  referenced. control period with 'hbase.master.mob.cleaner.period'- Optionally, RS that are compacting mob files can limit write  amplification by not rewriting values from mob hfiles over a certain size  limit. opt-in by setting 'hbase.mob.compaction.type' to 'optimized'.  control threshold by 'hbase.mob.compactions.max.file.size'.  default is 1GiB- Should smoothly integrate with existing MOB users via rolling upgrade.  will delay old MOB file cleanup until per-region compaction has managed  to compact each region at least once so that used mob hfile metadata can  be gathered.",hbase.mob.major.compaction.region.batch.size hbase.mob.compaction.type hbase.mob.compactions.max.file.size hbase.unsafe.mob.discard.miss hbase.mob.min.age.archive
SPARK-23380,https://github.com/apache/spark/commit/d6632d185e147fcbe6724545488ad80dce20277e,Add code change,[PYTHON] Adds a conf for Arrow fallback in toPandas/createDataFrame with Pandas DataFrame,spark.sql.execution.arrow.fallback.enabled
SPARK-19753,https://github.com/apache/spark/commit/dccc0aa3cf957c8eceac598ac81ac82f03b52105,Add code change,Un-register all shuffle output on a host in case of slave lost or fetch failure,spark.files.fetchFailure.unRegisterOutputOnHost
SPARK-20236,https://github.com/apache/spark/commit/a66fe36cee9363b01ee70e469f1c968f633c5713,Add code change,[SQL] dynamic partition overwrite,spark.sql.sources.partitionOverwriteMode
SPARK-20648,https://github.com/apache/spark/commit/4741c07809393ab85be8b4a169d4ed3da93a4781,Add code change,[CORE] Port JobsTab and StageTab to the new UI backend.,spark.ui.dagGraph.retainedRootRDDs
SPARK-21127,https://github.com/apache/spark/commit/61b5df567eb8ae0df4059cb0e334316fff462de9,Add code change,Update statistics after data changing commands,spark.sql.statistics.autoUpdate.size
SPARK-21243,https://github.com/apache/spark/commit/ef617755868077dbc57de4e7edea8f01335f5556,Add code change,Limit no. of map outputs in a shuffle fetch,spark.reducer.maxBlocksInFlightPerAddress
SPARK-21527,https://github.com/apache/spark/commit/574ef6c987c636210828e96d2f797d8f10aff05e,Add code change,Use buffer limit in order to use JAVA NIO Util's ……buffercache,spark.buffer.write.chunkSize
SPARK-21603,https://github.com/apache/spark/commit/1cce1a3b639c5c793d43fa51a8ec3e0fef622a40,Add code change,The wholestage codegen will be much slower then th……at is closed when the function is too long,spark.sql.codegen.maxLinesPerFunction
SPARK-22535,https://github.com/apache/spark/commit/03f2b7bff7e537ec747b41ad22e448e1c141f0dd,Add code change,[PYSPARK] Sleep before killing the python worker in PythonRunner.MonitorThread,spark.python.task.killTimeout
SPARK-22537,https://github.com/apache/spark/commit/efd0036ec88bdc385f5a9ea568d2e2bbfcda2912,Add code change,[CORE] Aggregation of map output statistics on driver faces single point bottleneck,spark.shuffle.mapOutput.parallelAggregationThreshold
SPARK-23668,https://github.com/apache/spark/commit/cccaaa14ad775fb981e501452ba2cc06ff5c0f0a,Add code change,[K8S] Add **CONFIG** option for passing through k8s Pod.specimagePullSecrets,spark.kubernetes.container.image.pullSecrets
SPARK-24156,https://github.com/apache/spark/commit/47b5b68528c154d32b3f40f388918836d29462b8,Add code change,[SS] Enabled no-data batches in MicroBatchExecution for streaming aggregation and deduplication.,spark.sql.streaming.noDataMicroBatchesEnabled
SPARK-24626,https://github.com/apache/spark/commit/d36539741ff6a12a6acde9274e9992a66cdd36e7,Add code change,Improve location size calculation in Analyze Table command,spark.sql.parallelFileListingInStatsComputation.enabled
SPARK-25457,https://github.com/apache/spark/commit/47d6e80a2e64823fabb596503fb6a6cc6f51f713,Add code change,IntegralDivide returns data type of the operands,spark.sql.legacy.integralDivide.returnBigint
SPARK-26089,https://github.com/apache/spark/commit/688b0c01fac0db80f6473181673a89f1ce1be65b,Add code change,Handle corruption in large shuffle blocks,spark.shuffle.detectCorrupt.useExtraMemory
SPARK-26178,https://github.com/apache/spark/commit/f982ca07e80074bdc1e3b742c5e21cf368e4ede2,Add code change,Use java.time API for parsing timestamps and dates from CSV,spark.sql.legacy.timeParser.enabled
SPARK-26902,https://github.com/apache/spark/commit/b0450d07bd5a77a519a662351ca5b5d562e61a58,Add code change,Support java.time.Instant as an external type of TimestampType,spark.sql.catalyst.timestampType
SPARK-27008,https://github.com/apache/spark/commit/8e5f9995cad409799f3646b3d03761a771ea1664,Add code change,Support java.time.LocalDate as an external type of…… DateType,spark.sql.datetime.java8API.enabled
SPARK-27045,https://github.com/apache/spark/commit/e60d8fce0b0cf2a6d766ea2fc5f994546550570a,Add code change,SQL tab in UI shows actual SQL instead of callsite in case of SparkSQLDriver,spark.sql.event.truncate.length
SPARK-27394,https://github.com/apache/spark/commit/5ff39cd5ee92da0d08380c7a680d350ff6f4b5db,Add code change,Flush LiveEntity if necessary when receiving SparkListenerExecutorMetricsUpdate,spark.ui.liveUpdate.minFlushPeriod
SPARK-27588,https://github.com/apache/spark/commit/618d6bff71073c8c93501ab7392c3cc579730f0b,Add code change,Binary file data source fails fast and doesn't attempt to read very large files,spark.sql.sources.binaryFile.maxLength
SPARK-27638,https://github.com/apache/spark/commit/66f5a42ca5d259038f0749ae2b9a04cc2f658880,Add code change,Cast string to date/timestamp in binary comparisons with dates/timestamps,spark.sql.legacy.typeCoercion.datetimeToString
SPARK-27693,https://github.com/apache/spark/commit/bc46feaced9f6694d4829af3cf5637bb1272ef77,Add code change,Add default catalog property,spark.sql.default.catalog
SPARK-27754,https://github.com/apache/spark/commit/1a8c09334db87b0e938c38cd6b59d326bdcab3c3,Add code change,Introduce additional config (spark.kubernetes.driver.request.cores) for driver request cores for spark on k8s,spark.kubernetes.driver.request.cores
SPARK-28052,https://github.com/apache/spark/commit/5ae1a6bf0dea9e74ced85686ef33a87cfa3e90c2,Add code change,Make `ArrayExists` follow the three-valued boolean logic.,spark.sql.legacy.arrayExistsFollowsThreeValuedLogic
SPARK-20981,https://github.com/apache/spark/commit/06c0544113ba77857c5cb1bbf94dcaf21d0b01af,Add code change,Add new **CONFIG**uration spark.jars.repositor……ies as equivalence of --repositories,spark.jars.repositories
SPARK-28118,https://github.com/apache/spark/commit/47f54b1ec717d0d744bf3ad46bb1ed3542b667c8,Add code change,[CORE] Add `spark.eventLog.compression.codec` configuration,spark.eventLog.compression.codec
SPARK-16019,https://github.com/apache/spark/commit/1cad31f00644d899d8e74d58c6eb4e9f72065473,Add code change,Use separate RM poll interval when starting clien……t AM.,spark.yarn.clientLaunchMonitorInterval
SPARK-16060,https://github.com/apache/spark/commit/eaac60a1e20e29084b7151ffca964cfaa5ba99d1,Add code change,[SQL][FOLLOW-UP] add a wrapper solution for vectorized orc reader,spark.sql.orc.copyBatchToSpark
SPARK-17091,https://github.com/apache/spark/commit/e1de34113e057707dfc5ff54a8109b3ec7c16dfb,Add code change,[SQL] Add rule to convert IN predicate to equivalent Parquet filter,spark.sql.parquet.pushdown.inFilterThreshold
SPARK-18580,https://github.com/apache/spark/commit/2b89e4aa2e8bd8b88f6e5eb60d95c1a58e5c4ace,Add code change,[DSTREAM][KAFKA] Add spark.streaming.backpressure.initialRate to direct Kafka streams,spark.streaming.backpressure.initialRate
SPARK-19606,https://github.com/apache/spark/commit/b3f9dbf48ec0938ff5c98833bb6b6855c620ef57,Add code change,[MESOS] Support constraints in spark-dispatcher,spark.mesos.driver.constraints
SPARK-20644,https://github.com/apache/spark/commit/c7f38e5adb88d43ef60662c5d6ff4e7a95bff580,Add code change,[core] Initial ground work for kvstore UI backend.,spark.ui.liveUpdate.period
SPARK-22187,https://github.com/apache/spark/commit/b3d88ac02940eff4c867d3acb79fe5ff9d724e83,Add code change,[SS] Update unsaferow format for saved state in flatMapGroupsWithState to allow timeouts with deleted state,spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion
SPARK-22188,https://github.com/apache/spark/commit/5a07aca4d464e96d75ea17bf6768e24b829872ec,Add code change,"[CORE] Adding security headers for preventing XSS, MitM and MIME sniffing",spark.ui.xXssProtection spark.ui.xContentTypeOptions.enabled spark.ui.strictTransportSecurity
SPARK-22683,https://github.com/apache/spark/commit/55c4ca88a3b093ee197a8689631be8d1fac1f10f,Add code change,[CORE] Add a executorAllocationRatio **PARAMETER** to throttle the parallelism of the dynamic allocation,spark.dynamicAllocation.executorAllocationRatio
SPARK-22790,https://github.com/apache/spark/commit/ba891ec993c616dc4249fc786c56ea82ed04a827,Add code change,[SQL] add a **CONFIG**urable factor to describe HadoopFsRelation's size,spark.sql.sources.fileCompressionFactor
SPARK-22994,https://github.com/apache/spark/commit/0b2eefb674151a0af64806728b38d9410da552ec,Add code change,[K8S] Use a single image for all Spark containers.,spark.kubernetes.container.image
SPARK-23196,https://github.com/apache/spark/commit/49b0207dc9327989c72700b4d04d2a714c92e159,Add code change,Unify continuous and microbatch V2 sinks,spark.sql.streaming.disabledV2Writers
SPARK-23285,https://github.com/apache/spark/commit/fe2b7a4568d65a62da6e6eb00fff05f248b4332c,Add code change,[K8S] Add a **CONFIG** property for specifying physical executor cores,spark.kubernetes.executor.request.cores
SPARK-23836,https://github.com/apache/spark/commit/ddc2052ebd247aa2a8dad34fd5c1cd345fa45118,Add code change,"Support returning StructType to the level support in GroupedMap Arrow's ""scalar"" UDFS (or similar)",spark.sql.legacy.execution.pandas.groupedMap.assignColumnsByName
SPARK-24063,https://github.com/apache/spark/commit/c4bbfd177b4e7cb46f47b39df9fd71d2d9a12c6d,Add code change,Add maximum epoch queue threshold for ContinuousExecution,spark.sql.streaming.continuous.epochBacklogQueueSize
SPARK-24193,https://github.com/apache/spark/commit/8a837bf4f3f2758f7825d2362cf9de209026651a,Add code change,create TakeOrderedAndProjectExec only when the limit number is below spark.sql.execution.topKSortFallbackThreshold,spark.sql.execution.topKSortFallbackThreshold
SPARK-24296,https://github.com/apache/spark/commit/99d2e4e00711cffbfaee8cb3da9b6b3feab8ff18,Add code change,Replicate large blocks as a stream.,spark.storage.memoryMapLimitForTests
SPARK-24586,https://github.com/apache/spark/commit/03c9e8adeece2c371cef9e442f8630c52e09ecfb,Add code change,Upcast should not allow casting from string to other types,spark.sql.legacy.looseUpcast
SPARK-24605,https://github.com/apache/spark/commit/d08f53dc61f662f5291f71bcbe1a7b9f531a34d2,Add code change,[SQL] size(null) returns null instead of -1,spark.sql.legacy.sizeOfNull
SPARK-24836,https://github.com/apache/spark/commit/106880edcd67bc20e8610a16f8ce6aa250268eeb,Add code change,[SQL] New option for Avro datasource - ignoreExtension,ignoreExtension
SPARK-25004,https://github.com/apache/spark/commit/7ad18ee9f26e75dbe038c6034700f9cd4c0e2baa,Add code change,Add spark.executor.pyspark.memory limit.,spark.executor.pyspark.memory
SPARK-25021,https://github.com/apache/spark/commit/1cfda448255d5b4a0df88148e0f6acd88aa6e318,Add code change,Add spark.executor.pyspark.memory limit for K8S,spark.kubernetes.resource.type
SPARK-25174,https://github.com/apache/spark/commit/f8346d2fc01f1e881e4e3f9c4499bf5f9e3ceb3f,Add code change,Limit the size of diagnostic message for am to unregister itself from rm,spark.yarn.am.finalMessageLimit
SPARK-25454,https://github.com/apache/spark/commit/d0990e3dfee752a6460a6360e1a773138364d774,Add code change,add a new **CONFIG** for picking minimum precision for…… integral literals,spark.sql.legacy.literal.pickMinimumPrecision
SPARK-25811,https://github.com/apache/spark/commit/f92d2766535d882b17f6d3b061d1df57bc84a90e,Add code change,Raise a proper error when unsafe cast is detected by PyArrow,spark.sql.execution.pandas.arrowSafeTypeConversion
SPARK-25887,https://github.com/apache/spark/commit/c542c247bbfe1214c0bf81076451718a9e8931dc,Add code change,Allow specifying Kubernetes context to use,spark.kubernetes.context
SPARK-26322,https://github.com/apache/spark/commit/6daa78309460e338dd688cf6cdbd46a12666f72e,Add code change,Add spark.kafka.sasl.token.mechanism to ease delegation token **CONFIG**uration.,spark.kafka.sasl.token.mechanism
SPARK-26688,https://github.com/apache/spark/commit/caceaec93203edaea1d521b88e82ef67094cdea9,Add code change,Provide configuration of initially blacklisted YARN nodes,spark.yarn.exclude.nodes
SPARK-28177,https://github.com/apache/spark/commit/cec6a329044fa7d8a4f3da3871dbacac95cc38e,Add code change,[SQL] Adjust post shuffle partition number in adaptive execution,spark.sql.adaptive.reducePostShufflePartitions.enabled spark.sql.adaptive.maxNumPostShufflePartitions
SPARK-28294,https://github.com/apache/spark/commit/bbc2be4f425c4c26450e1bf21db407e81046ce2,Add code change,[CORE] Support `spark.history.fs.cleaner.maxNum` **CONFIGURATION,spark.history.fs.cleaner.maxNum
SPARK-27919,https://github.com/apache/spark/commit/ec821b4411bf64ab587548853ade08c053c64d6,Add code change,[SQL] Add v2 session catalog,spark.sql.catalog.session
SPARK-23472,https://github.com/apache/spark/commit/f83000597f250868de9722d8285fed013abc5ec,Add code change,[CORE] Add defaultJavaOptions for driver and executor.,spark.driver.defaultJavaOptions spark.executor.defaultJavaOptions
SPARK-27707,https://github.com/apache/spark/commit/127bc899ae78d73332a87f0972b5db3c9936c1f,Add code change,[SQL] Prune unnecessary nested fields from Generate,spark.sql.optimizer.expression.nestedPruning.enabled
SPARK-26218,https://github.com/apache/spark/commit/ee41001949af43d25dc6962ab6ca277e53c6429,Add code change,[SQL] Overflow on arithmetic operations returns incorrect result,spark.sql.arithmeticOperations.failOnOverFlow
SPARK-28651,https://github.com/apache/spark/commit/5bb69945e4aaf519cd10a5c5083332f618039af,Add code change,[SS] Force the schema of Streaming file source to be nullable,spark.sql.streaming.fileSource.schema.forceNullable
SPARK-28487,https://github.com/apache/spark/commit/0343854f54b48b206ca434accec99355011560c,Add code change,[K8S] More responsive dynamic allocation with K8SThis change implements a few changes to the k8s pod allocator sothat it behaves a little better when dynamic allocation is on.,spark.kubernetes.dynamicAllocation.deleteGracePeriod
SPARK-28573,https://github.com/apache/spark/commit/d5688dc732890923c326f272b0c18c329a69459,Add code change,[SQL] Convert InsertIntoTable(HiveTableRelation) to DataSource inserting for partitioned table,spark.sql.hive.convertInsertingPartitionedTable
SPARK-25341,https://github.com/apache/spark/commit/f725d472f51fb80c6ce1882ec283ff69bafb0de,Add code change,"[CORE] Support rolling back a shuffle map stage and re-generate the shuffle filesAfter the newly added shuffle block fetching protocol in #24565, we can keep this work by extending the FetchShuffleBlocks message.",spark.shuffle.useOldFetchProtocol
SPARK-26848,https://github.com/apache/spark/commit/4513f1c0dc450e9249d43fdad618fdcaf8d399b,Add code change,[SQL][SS] Introduce new **OPTION** to Kafka source: offset by timestamp (starting/ending),startingOffsetsByTimestamp endingOffsetsByTimestamp
SPARK-29182,https://github.com/apache/spark/commit/4ecbdbb6a7bd3908da32c82832e886b4f9f9e59,Add code change,[CORE] Cache preferred locations of checkpointed RDD,spark.rdd.checkpoint.cachePreferredLocsExpireTime
SPARK-26154,https://github.com/apache/spark/commit/c941362cb94b24bdf48d4928a1a4dff1b13a148,Add code change,[SS] Streaming left/right outer join should not return outer nulls for already matched rows,spark.sql.streaming.join.stateFormatVersion
SPARK-29568,https://github.com/apache/spark/commit/363af16c72abe19fc5cc5b5bdf9d8dc34975f2b,Add code change,[SS] Stop existing running streams when a new stream is launched,spark.sql.streaming.stopActiveRunOnRestart
SPARK-29956,https://github.com/apache/spark/commit/87ebfaf003fcd05a7f6d23b3ecd4661409ce5f2,Add code change,[SQL] A literal number with an exponent should be parsed to Double,spark.sql.legacy.exponentLiteralToDecimal.enabled
SPARK-29976,https://github.com/apache/spark/commit/ad238a2238a9d0da89be4424574436cbfaee579,Add code change,[CORE] Trigger speculation for stages with too few tasks,spark.speculation.task.duration.threshold
SPARK-30143,https://github.com/apache/spark/commit/4c37a8a3f4a489b52f1919d2db84f6e32c6a05c,Add code change,[SS] Add a timeout on stopping a streaming query,spark.sql.streaming.stopTimeout
SPARK-27963,https://github.com/apache/spark/commit/2ddeff97d7329942a98ef363991eeabc3fa71a7,Add new code,[CORE] Allow dynamic allocation without a shuffle service.,spark.dynamicAllocation.shuffleTimeout
SPARK-11035,https://github.com/apache/spark/commit/cfcd746689c2b84824745fa6d327ffb584c7a17d,Add new code,[CORE] Add in-process Spark app launcher.,spark.launcher.port spark.launcher.secret
SPARK-27362,https://github.com/apache/spark/commit/1277f8fa92da85d9e39d9146e3099fcb75c71a8f,Add new code,Resource Scheduling support for k8s,spark.driver.resource.{resourceName}.vendor spark.executor.resource.{resourceName}.vendor
SPARK-27783,https://github.com/apache/spark/commit/1ada36b5717f6446f0bc67fbad7c5e12796500b6,Add new code,[SQL] Add customizable hint error handler,hintErrorHandler
SPARK-12139,https://github.com/apache/spark/commit/2cbfc975ba937a4eb761de7a6473b7747941f386,Add new code,REGEX Column Specification,spark.sql.parser.quotedRegexColumnNames
SPARK-12297,https://github.com/apache/spark/commit/acf7ef3154e094875fa89f30a78ab111b267db91,Add new code,[SQL] Adjust timezone for int96 data from impala,spark.sql.parquet.int96TimestampConversion
SPARK-13534,https://github.com/apache/spark/commit/d03aebbe6508ba441dc87f9546f27aeb27553d77,Add new code,Using Apache Arrow to increase performance of ……DataFrame.toPandas,spark.sql.execution.arrow.enable spark.sql.execution.arrow.maxRecordsPerBatch
SPARK-13669,https://github.com/apache/spark/commit/9e50a1d37a4cf0c34e20a7c1a910ceaff41535a2,Add new code,Improve the blacklist mechanism to h……andle external shuffle service unavailable situation,spark.blacklist.application.fetchFailure.enabled
SPARK-16060,https://github.com/apache/spark/commit/f44ba910f58083458e1133502e193a9d6f2bf766,Add new code,[SQL] Support Vectorized ORC Reader,spark.sql.orc.enableVectorizedReader
SPARK-16501,https://github.com/apache/spark/commit/7f10cf83f311526737fc96d5bb8281d12e41932f,Add new code,[MESOS] Allow providing Mesos principal & secret via files,spark.mesos.secret.file spark.mesos.principal.file
SPARK-16630,https://github.com/apache/spark/commit/b56e9c613fb345472da3db1a567ee129621f6bf3,Add new code,[YARN] Blacklist a node if executors won't launch on it,spark.yarn.blacklist.executor.launch.blacklisting.enabled
SPARK-17074,https://github.com/apache/spark/commit/11b60af737a04d931356aa74ebf3c6cf4a6b08d6,Add new code,[SQL] Generate equi-height histogram in column statistics,spark.sql.statistics.histogram.enabled spark.sql.statistics.histogram.numBins spark.sql.statistics.percentile.accuracy
SPARK-17147,https://github.com/apache/spark/commit/eac0b067222a3dfa52be20360a453cb7bd420bf2,Add new code,[STREAMING][KAFKA] Allow non-consecutive offsets,spark.streaming.kafka.allowNonConsecutiveOffsets
SPARK-18278,https://github.com/apache/spark/commit/e9b2070ab2d04993b1c0c1d6c6aba249e6664c8d,Add new code,[SCHEDULER] Spark on Kubernetes - Basic Scheduler Backend,spark.kubernetes.namespace spark.kubernetes.executor.docker.image spark.kubernetes.docker.image.pullPolicy spark.kubernetes.authenticate.driver.serviceAccountName spark.kubernetes.driver.pod.name spark.kubernetes.executor.podNamePrefix spark.kubernetes.executor.memoryOverhead spark.kubernetes.allocation.batch.size spark.kubernetes.allocation.batch.delay spark.kubernetes.executor.limit.cores spark.kubernetes.executor.lostCheck.maxAttempts
SPARK-19112,https://github.com/apache/spark/commit/444bce1c98c45147fe63e2132e9743a0c5e49598,Add new code,[CORE] Support for ZStandard codec,spark.io.compression.zstd.bufferSize spark.io.compression.zstd.level
SPARK-19355,https://github.com/apache/spark/commit/4f175850985cfc4c64afb90d784bb292e81dc0b7,Add new code,Use map output statistics to improve global limit'……s parallelism,spark.sql.limit.flatGlobalLimit
SPARK-19724,https://github.com/apache/spark/commit/249007e37f51f00d14e596692aeac87fbc10b520,Add new code,SQL] create a managed table with an existed default tabe should throw an exception,spark.sql.allowCreatingManagedTableUsingNonemptyLocation
SPARK-20327,https://github.com/apache/spark/commit/3946de773498621f88009c309254b019848ed490,Add new code,"Add CLI support for YARN custom resources, like GPUs",spark.yarn.am.resource spark.yarn.driver.resource spark.yarn.executor.resource
SPARK-20653,https://github.com/apache/spark/commit/772e4648d95bda3353723337723543c741ea8476,Add new code,[CORE] Add cleaning of old elements from the status store.,spark.appStateStore.asyncTracking.enable spark.ui.retainedDeadExecutors
SPARK-20654,https://github.com/apache/spark/commit/8b497046c647a21bbed1bdfbdcb176745a1d5cd5,Add new code,[CORE] Add **CONFIG** to limit disk usage of the history server.,spark.history.store.maxDiskUsage
SPARK-20812,https://github.com/apache/spark/commit/fc45c2c88a838b8f46659ebad2a8f3a9923bc95f,Add new code,Add secrets support to the dispatcher,spark.mesos.driver.secret.names spark.mesos.driver.secret.values spark.mesos.driver.secret.envkeys spark.mesos.driver.secret.filenames
SPARK-20863,https://github.com/apache/spark/commit/2a23cdd078a7409d0bb92cf27718995766c41b1d,Add new code,Add metrics/instrumentation to LiveListenerBus,spark.scheduler.listenerbus.metrics.maxListenerClassesTimed
SPARK-20871,https://github.com/apache/spark/commit/2a53fbfce72b3faef020e39a1e8628d68bc95beb,Add new code,limit logging of Janino code,spark.sql.codegen.logging.maxLines
SPARK-21000,https://github.com/apache/spark/commit/8da3f7041aafa71d7596b531625edb899970fec2,Add new code,Add Mesos labels support to the Spark Dispatcher,spark.mesos.driver.labels
SPARK-21113,https://github.com/apache/spark/commit/1e978b17d63d7ba20368057aa4e65f5ef6e87369,Add new code,[CORE] Read ahead input stream to amortize disk IO cost,spark.unsafe.sorter.spill.read.ahead.fraction spark.unsafe.sorter.spill.read.ahead.enabled
SPARK-21595,https://github.com/apache/spark/commit/94439997d57875838a8283c543f9b44705d3a503,Add new code,Separate thresholds for buffering and spilling in Exter……nalAppendOnlyUnsafeRowArray,spark.sql.windowExec.buffer.in.memory.threshold spark.sql.sortMergeJoinExec.buffer.in.memory.threshold spark.sql.cartesianProductExec.buffer.in.memory.threshold
SPARK-21694,https://github.com/apache/spark/commit/ce0d3bb377766bdf4df7852272557ae846408877,Add new code,Support Mesos CNI network labels,spark.mesos.network.name spark.mesos.network.labels
SPARK-21717,https://github.com/apache/spark/commit/d20bbc2d87ae6bd56d236a7c3d036b52c5f20ff5,Add new code,[SQL] Decouple consume functions of physical operators in whole-stage codegen,spark.sql.codegen.splitConsumeFuncByOperator
SPARK-21917,https://github.com/apache/spark/commit/8319432af60b8e1dc00f08d794f7d80591e24d0c,Add new code,[CORE][YARN] Supporting adding http(s) resources in yarn mode,spark.yarn.dist.forceDownloadSchemes
SPARK-22036,https://github.com/apache/spark/commit/e28eb431146bcdcaf02a6f6c406ca30920592a6a,Add new code,[SQL] Decimal multiplication with high precision/scale often returns NULL,spark.sql.decimalOperations.allowPrecisionLoss
SPARK-22148,https://github.com/apache/spark/commit/fdd3bace1da01e5958fe0345c38e889e740ce25e,Add new code,TaskSetManager.abortIfCompletelyBlacklisted should not abort when all current executors are blacklisted but dynamic allocation is enabled,spark.scheduler.blacklist.unschedulableTaskSetTimeout
SPARK-22290,https://github.com/apache/spark/commit/dc2714da50ecba1bf1fdf555a82a4314f763a76e,Add new code,[CORE] Avoid creating Hive delegation tokens when not necessary.,spark.yarn.kerberos.relogin.period
SPARK-22395,https://github.com/apache/spark/commit/64817c423c0d82a805abd69a3e166e5bfd79c739,Add new code,[SQL][PYTHON] Fix the behavior of timestamp values for Pandas to respect session timezone,spark.sql.execution.pandas.respectSessionTimeZone
SPARK-22404,https://github.com/apache/spark/commit/f06bc0cd1dee2a58e04ebf24bf719a2f7ef2dc4e,Add new code,Provide an option to use unmanaged AM in yarn-client mode,spark.yarn.unmanagedAM.enabled
SPARK-22646,https://github.com/apache/spark/commit/3f4060c340d6bac412e8819c4388ccba226efcf3,Add new code,[K8S] Spark on Kubernetes - basic submission client,spark.kubernetes.submission.waitAppCompletion spark.kubernetes.report.interval spark.kubernetes.mountDependencies.jarsDownloadDir spark.kubernetes.mountDependencies.filesDownloadDir
SPARK-22757,https://github.com/apache/spark/commit/171f6ddadc6185ffcc6ad82e5f48952fb49095b2,Add new code,"[KUBERNETES] Enable use of remote dependencies (http, s3……, gcs, etc.) in Kubernetes mode",spark.kubernetes.initContainer.image spark.kubernetes.mountDependencies.timeout spark.kubernetes.mountDependencies.maxSimultaneousDownloads spark.kubernetes.initContainer.remoteJars spark.kubernetes.initContainer.remoteFiles spark.kubernetes.initContainer.configMapName spark.kubernetes.initContainer.configMapKey
SPARK-22771,https://github.com/apache/spark/commit/f2b3525c17d660cf6f082bbafea8632615b4f58e,Add new code,SQL] Concatenate binary inputs into a binary output,spark.sql.function.concatBinaryAsString
SPARK-22789,https://github.com/apache/spark/commit/8941a4abcada873c26af924e129173dc33d66d71,Add new code,Map-only continuous processing execution,spark.sql.streaming.continuous.executorQueueSize spark.sql.streaming.continuous.executorPollIntervalMs
SPARK-22880,https://github.com/apache/spark/commit/2333a34d390f2fa19b939b8007be0deb31f31d3c,Add new code,[SQL] Add cascadeTruncate option to JDBC datasource,cascadeTruncate
SPARK-22937,https://github.com/apache/spark/commit/e8af7e8aeca15a6107248f358d9514521ffdc6d3,Add new code,[SQL] SQL elt output binary for binary inputs,spark.sql.function.eltOutputAsString
SPARK-23032,https://github.com/apache/spark/commit/e57f394818b0a62f99609e1032fede7e981f306f,Add new code,Add a per-query codegenStageId to WholeStageCodegenExec,spark.sql.codegen.useIdInClassName
SPARK-23128,https://github.com/apache/spark/commit/c79f471d0475fd98ddeb1e6281551e42684837d2,Add new code,A new approach to do adaptive execution in Spark SQL,spark.sql.runtime.reoptimization.enabled
SPARK-23146,https://github.com/apache/spark/commit/571a6f0574e50e53cea403624ec3795cd03aa204,Add new code,Support client mode.,spark.kubernetes.authenticate.caCertFile spark.kubernetes.authenticate.serviceAccountName spark.kubernetes.authenticate.clientKeyFile spark.kubernetes.authenticate.clientCertFile spark.kubernetes.authenticate.oauthToken spark.kubernetes.authenticate.oauthTokenFile
SPARK-23153,https://github.com/apache/spark/commit/5e74570c8f5e7dfc1ca1c53c177827c5cea57bf1,Add new code,Support client dependencies with a Hadoop Compatib……le File System,spark.kubernetes.file.upload.path
SPARK-23173,https://github.com/apache/spark/commit/2ca9bb083c515511d2bfee271fc3e0269aceb9d5,Add new code,[SQL] Avoid creating corrupt parquet files when loading data from JSON,spark.sql.fromJsonForceNullableSchema
SPARK-23207,https://github.com/apache/spark/commit/94c67a76ec1fda908a671a47a2a1fa63b3ab1b06,Add new code,[SQL] Shuffle+Repartition on a DataFrame could lead to incorrect answers,spark.sql.execution.sortBeforeRepartition
SPARK-23257,https://github.com/apache/spark/commit/6c9c84ffb9c8d98ee2ece7ba4b010856591d383d,Add new code,Kerberos Support for Spark on K8S,spark.kubernetes.kerberos.krb5.path spark.kubernetes.kerberos.krb5.configMapName spark.kubernetes.hadoop.configMapName spark.kubernetes.kerberos.tokenSecret.name spark.kubernetes.kerberos.tokenSecret.itemKey
SPARK-23362,https://github.com/apache/spark/commit/0a73aa31f41c83503d5d99eff3c9d7b406014ab3,Add new code,[SS] Migrate Kafka Microbatch source to v2,spark.sql.streaming.disabledV2MicroBatchReaders
SPARK-23429,https://github.com/apache/spark/commit/9241e1e7e66574cfafa68791771959dfc39c9684,Add new code,Add executor memory metrics to heartbeat and expose in executors REST API,spark.eventLog.logStageExecutorMetrics.enabled
SPARK-23529,https://github.com/apache/spark/commit/5ff1b9ba1983d5601add62aef64a3e87d07050eb,Add new code,[K8S] Support mounting volumes,spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.path spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.options.claimName spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.path spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.options.claimName
SPARK-23549,https://github.com/apache/spark/commit/e4bec7cb88b9ee63f8497e3f9e0ab0bfa5d5a77c,Add new code,[SQL] Cast to timestamp when comparing timestamp with date,spark.sql.typeCoercion.compareDateTimestampInTimestamp
SPARK-23711,https://github.com/apache/spark/commit/a40ffc656d62372da85e0fa932b67207839e7fde,Add new code,[SQL] Add fallback generator for UnsafeProjection,spark.sql.codegen.factoryMode
SPARK-23715,https://github.com/apache/spark/commit/417ad92502e714da71552f64d0e1257d2fd5d3d0,Add new code,[SQL] the input of to/from_utc_timestamp can not have timezone,spark.sql.function.rejectTimezoneInString
SPARK-23727,https://github.com/apache/spark/commit/b02e76cbffe9e589b7a4e60f91250ca12a4420b2,Add new code,[SQL] Support for pushing down filters for DateType in p arquet,spark.sql.parquet.filterPushdown.date
SPARK-23817,https://github.com/apache/spark/commit/c0632cec04e5b0f3fb3c3f27c21a2d3f3fbb4f7e,Add new code,Create file source V2 framework and migrate ORC re……ad path,spark.sql.sources.read.useV1SourceList
SPARK-23966,https://github.com/apache/spark/commit/cbb41a0c5b01579c85f06ef42cc0585fbef216c5,Add new code,SS] Refactoring all checkpoint file writing logic in a common CheckpointFileManager interface,spark.sql.streaming.checkpointFileManagerClass
SPARK-23984,https://github.com/apache/spark/commit/1a644afbac35c204f9ad55f86999319a9ab458c6,Add new code,[K8S] Initial Python Bindings for PySpark on K8s,spark.kubernetes.python.pyFiles spark.kubernetes.python.mainAppResource spark.kubernetes.python.appArgs spark.kubernetes.memoryOverheadFactor spark.kubernetes.pyspark.pythonversion
SPARK-24215,https://github.com/apache/spark/commit/dbb4d83829ec4b51d6e6d3a96f7a4e611d8827bc,Add new code,[PYSPARK] Implement _repr_html_ for dataframes in PySpark,spark.sql.repl.eagerEval.enabled spark.sql.repl.eagerEval.maxNumRows spark.sql.repl.eagerEval.truncate
SPARK-24215,https://github.com/apache/spark/commit/6a0b77a55d53e74ac0a0892556c3a7a933474948,Add new code,PYSPARK][FOLLOW UP] Implement eager evaluation for DataFrame APIs in PySpark,spark.sql.repl.eagerEval.enabled spark.sql.repl.eagerEval.maxNumRows spark.sql.repl.eagerEval.truncate
SPARK-24232,https://github.com/apache/spark/commit/21e1fc7d4aed688d7b685be6ce93f76752159c98,Add new code,[K8S] Add support for secret env vars,spark.kubernetes.driver.secretKeyRef.ENV_VAR spark.kubernetes.executor.secrets.ENV_VAR
SPARK-24244,https://github.com/apache/spark/commit/64fad0b519cf35b8c0a0dec18dd3df9488a5ed25,Add new code,[SQL] Passing only required columns to the CSV parser,spark.sql.csv.parser.columnPruning.enabled
SPARK-24248,https://github.com/apache/spark/commit/270a9a3cac25f3e799460320d0fc94ccd7ecfaea,Add new code,[K8S] Use level triggering and state reconciliation in scheduling and lifecycle,spark.kubernetes.executor.apiPollingInterval spark.kubernetes.executor.eventProcessingInterval
SPARK-24326,https://github.com/apache/spark/commit/22df953f6bb191858053eafbabaa5b3ebca29f56,Add new code,[MESOS] add support for local:// scheme for the app jar,spark.mesos.appJar.local.resolution.mode
SPARK-24340,https://github.com/apache/spark/commit/8ef167a5f9ba8a79bb7ca98a9844fe9cfcfea060,Add new code,[CORE] Clean up non-shuffle disk block manager files following executor exits on a Standalone cluster,spark.storage.cleanupFilesAfterExecutorExit
SPARK-24433,https://github.com/apache/spark/commit/ba84bcb2c4f73baf63782ff6fad5a607008c7cd2,Add new code,Initial R Bindings for SparkR on K8s,spark.kubernetes.r.mainAppResource spark.kubernetes.r.appArgs
SPARK-24434,https://github.com/apache/spark/commit/f6cc354d83c2c9a757f9b507aadd4dbdc5825cca,Add new code,Support user-specified driver and executor pod templates,spark.kubernetes.driver.podTemplateFile spark.kubernetes.executor.podTemplateFile spark.kubernetes.driver.podTemplateContainerName spark.kubernetes.executor.podTemplateContainerName
SPARK-24479,https://github.com/apache/spark/commit/7703b46d2843db99e28110c4c7ccf60934412504,Add new code,[SS] Added **CONFIG** for registering streamingQueryListeners,spark.sql.streaming.streamingQueryListeners
SPARK-24549,https://github.com/apache/spark/commit/9549a2814951f9ba969955d78ac4bd2240f85989,Add new code,Support Decimal type push down to the parquet data…… sources,spark.sql.parquet.filterPushdown.decimal
SPARK-24572,https://github.com/apache/spark/commit/ddd1b1e8aec023e61b186c494ccbc182db2eb3ca,Add new code,"""eager execution"" for R shell, IDE",spark.sql.repl.eagerEval.enabled
SPARK-24594,https://github.com/apache/spark/commit/d2436a85294a178398525c37833dae79d45c1452,Add new code,[YARN] Introducing metrics for YARN,spark.yarn.metrics.namespace
SPARK-24638,https://github.com/apache/spark/commit/03545ce6de08bd0ad685c5f59b73bc22dfc40887,Add new code,[SQL] StringStartsWith support push down,spark.sql.parquet.filterPushdown.string.startsWith
SPARK-24717,https://github.com/apache/spark/commit/8b7d4f842fdc90b8d1c37080bdd9b5e1d070f5c0,Add new code,[SS] Split out max retain version of state for memory in HDFSBackedStateStoreProvider,spark.sql.streaming.maxBatchesToRetainInMemory
SPARK-24718,https://github.com/apache/spark/commit/43e4e851b642bbee535d22e1b9e72ec6b99f6ed4,Add new code,[SQL] Timestamp support pushdown to parquet data source,spark.sql.parquet.filterPushdown.timestamp
SPARK-24730,https://github.com/apache/spark/commit/6078b891da8fe7fc36579699473168ae7443284c,Add new code,[SS] Add policy to choose max as global watermark when streaming query has multiple watermarks,spark.sql.streaming.multipleWatermarkPolicy
SPARK-24763,https://github.com/apache/spark/commit/6c5cb85856235efd464b109558896f81ae2c4c75,Add new code,Remove redundant key data from value in streaming aggregation,spark.sql.streaming.aggregation.stateFormatVersion
SPARK-24768,https://github.com/apache/spark/commit/395860a986987886df6d60fd9b26afd818b2cb39,Add new code,Have a built-in AVRO data source implementation,spark.sql.avro.compression.codec spark.sql.avro.deflate.level
SPARK-24773,https://github.com/apache/spark/commit/7cf16a7fa4eb4145c0c5d1dd2555f78a2fdd8d8b,Add new code,Avro: support logical timestamp type with different precisions,spark.sql.avro.outputTimestampType
SPARK-24793,https://github.com/apache/spark/commit/05168e725d2a17c4164ee5f9aa068801ec2454f4,Add new code,Enhance spark-submit for app management,spark.kubernetes.appKillPodDeletionGracePeriod
SPARK-24802,https://github.com/apache/spark/commit/434319e73f8cb6e080671bdde42a72228bd814ef,Add new code,Add a new **CONFIG** for Optimization Rule Exclusion,spark.sql.optimizer.excludedRules
SPARK-24817,https://github.com/apache/spark/commit/388f5a0635a2812cd71b08352e3ddc20293ec189,Add new code,Implement BarrierTaskContext.barrier(),spark.barrier.sync.timeout
SPARK-24819,https://github.com/apache/spark/commit/bfb74394a5513134ea1da9fcf4a1783b77dd64e4,Add new code,Fail fast when no enough slots to launch the barrier stage on job submitted,spark.scheduler.barrier.maxConcurrentTasksCheck.interval spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures
SPARK-24918,https://github.com/apache/spark/commit/2f51e72356babac703cc20a531b4dcc7712f34af,Add new code,Executor Plugin API,spark.executor.plugins
SPARK-24920,https://github.com/apache/spark/commit/e103c4a5e72bab8862ff49d6d4c1e62e642fc412,Add new code,Allow sharing Netty's memory pool allocators,spark.network.sharedByteBufAllocators.enabled spark.network.io.preferDirectBufs
SPARK-24958,https://github.com/apache/spark/commit/90c77ea3132d0b7a12c316bd42fb8d0f59bee253,Add new code,Add memory from procfs to executor metrics.,spark.eventLog.logStageExecutorProcessTreeMetrics.enabled
SPARK-24966,https://github.com/apache/spark/commit/73dd6cf9b558f9d752e1f3c13584344257ad7863,Add new code,Implement precedence rules for set operations.,spark.sql.legacy.setopsPrecedence.enabled
SPARK-25118,https://github.com/apache/spark/commit/5f11e8c4cb9a5db037ac239b8fcc97f3a746e772,Add new code,Need a solution to persist Spark application console outputs when running in shell/yarn client mode,spark.driver.log.dfsDir spark.driver.log.persistToDfs.enabled
SPARK-25262,https://github.com/apache/spark/commit/da6fa3828bb824b65f50122a8a0a0d4741551257,Add new code,Allow SPARK_LOCAL_DIRS to be tmpfs backed on K8S,spark.kubernetes.local.dirs.tmpfs
SPARK-25271,https://github.com/apache/spark/commit/5ad03607d1487e7ab3e3b6d00eef9c4028ed4975,Add new code,Hive ctas commands should use data source if it is…… convertible,spark.sql.hive.convertMetastoreCtas
SPARK-25394,https://github.com/apache/spark/commit/bd2c4471311cd7e948c80b4927a903636ce0ce7e,Add new code,Expose App status metrics as Source,spark.app.status.metrics.enabled
SPARK-25496,https://github.com/apache/spark/commit/1d20d13149140f53df307f47420740f45b4fa5f6,Add new code,Deprecate from_utc_timestamp and to_utc_timestamp,spark.sql.legacy.utcTimestampFunc.enabled
SPARK-25501,https://github.com/apache/spark/commit/0166c7373eee2654c49c210927e4e290d103f24f,Add new code,Add kafka delegation token support.,spark.kafka.bootstrap.servers spark.kafka.security.protocol spark.kafka.sasl.kerberos.service.name spark.kafka.ssl.truststore.location spark.kafka.ssl.truststore.password spark.kafka.ssl.keystore.location spark.kafka.ssl.keystore.password spark.kafka.ssl.key.password
SPARK-25708,https://github.com/apache/spark/commit/78e133141ce8131c60181f947346802864b0951a,Add new code,HAVING without GROUP BY means global aggregate,spark.sql.legacy.parser.havingWithoutGroupByAsWhere
SPARK-25839,https://github.com/apache/spark/commit/6cd23482d1ae8c6a9fe9817ed51ee2a039d46649,Add new code,Implement use of KryoPool in KryoSerializer,spark.kryo.pool
SPARK-25855,https://github.com/apache/spark/commit/af3b8160704b27dd8ed2b95b61edeec6968685be,Add new code,Don't use Erasure Coding for event log files,spark.eventLog.allowErasureCoding
SPARK-25865,https://github.com/apache/spark/commit/e5c502c596563dce8eb58f86e42c1aea2c51ed17,Add new code,Add GC information to ExecutorMetrics,spark.eventLog.gcMetrics.youngGenerationGarbageCollectors spark.eventLog.gcMetrics.oldGenerationGarbageCollectors
SPARK-25960,https://github.com/apache/spark/commit/3df307aa515b3564686e75d1b71754bbcaaf2dec,Add new code,Support subpath mounting with Kubernetes,spark.kubernetes.executor.volumes.[VolumeType].[VolumeName].mount.subPath
SPARK-26085,https://github.com/apache/spark/commit/ab2eafb3cdc7631452650c6cac03a92629255347,Add new code,"Key attribute of non-struct type under typed aggregation should be named as ""key"" too",spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue
SPARK-26205,https://github.com/apache/spark/commit/0c23a39384b7ae5fb4aeb4f7f6fe72007b84bbd2,Add new code,"Optimize InSet expression for bytes, shorts, ints, dates",spark.sql.optimizer.inSetSwitchThreshold
SPARK-26215,https://github.com/apache/spark/commit/967e4cb0112e2dd94bc75251c23bb9e854ee97a0,Add new code,define reserved keywords after SQL standard,spark.sql.parser.ansi.enabled
SPARK-26239,https://github.com/apache/spark/commit/57d6fbfa8c803ce1791e7be36aba0219a1fcaa63,Add new code,File-based secret key loading for SASL.,spark.authenticate.secret.file spark.authenticate.secret.driver.file spark.authenticate.secret.executor.file
SPARK-26263,https://github.com/apache/spark/commit/5a140b7844936cf2b65f08853b8cfd8c499d4f13,Add new code,Validate partition values with user provided schema,spark.sql.sources.validatePartitionColumns
SPARK-26288,https://github.com/apache/spark/commit/8b0aa59218c209d39cbba5959302d8668b885cf6,Add new code,add initRegisteredExecutorsDB,spark.shuffle.service.db.enabled
SPARK-26311,https://github.com/apache/spark/commit/ae5b2a6a92be4986ef5b8062d7fb59318cff6430,Add new code,New feature: apply custom log URL pattern for executor log URLs in SHS,spark.history.custom.executor.log.url spark.history.custom.executor.log.url.applyIncompleteApplication
SPARK-26595,https://github.com/apache/spark/commit/2a67dbfbd341af166b1c85904875f26a6dea5ba8,Add new code,Allow credential renewal based on kerberos ticket cache,spark.kerberos.renewal.credentials
SPARK-26673,https://github.com/apache/spark/commit/df4c53e44bc9837a470ec66486237403868cb04f,Add new code,File source V2 writes: create framework and migrate ORC,spark.sql.sources.write.useV1SourceList
SPARK-26792,https://github.com/apache/spark/commit/d5bda2c9e8dde6afc075cc7f65b15fa9aa82231c,Add new code,Apply custom log URL to Spark UI,spark.ui.custom.executor.log.url
SPARK-26837,https://github.com/apache/spark/commit/0f2c0b53e8fb18c86c67b5dd679c006db93f94a5,Add new code,Pruning nested fields from object serializers,spark.sql.optimizer.serializer.nestedSchemaPruning.enabled
SPARK-26941,https://github.com/apache/spark/commit/cad475dcc9376557f882859856286e858002389a,Add new code,Fix incorrect computation of maxNumExecutorFailur……es in ApplicationMaster for streaming,spark.streaming.dynamicAllocation.enabled spark.streaming.dynamicAllocation.testing spark.streaming.dynamicAllocation.minExecutors spark.streaming.dynamicAllocation.maxExecutors spark.streaming.dynamicAllocation.scalingInterval spark.streaming.dynamicAllocation.scalingUpRatio spark.streaming.dynamicAllocation.scalingDownRatio
SPARK-27024,https://github.com/apache/spark/commit/db2e3c43412e4a7fb4a46c58d73d9ab304a1e949,Add new code,Executor interface for cluster managers to support GPU and other resources,spark.driver.resource.count
SPARK-27088,https://github.com/apache/spark/commit/074533334d01afdd7862a1ac6c5a7a672bcce3f8,Add new code,"Apply conf ""spark.sql.optimizer.planChangeLog.level"" to batch plan change in RuleExecutor",spark.sql.optimizer.planChangeLog.batches
SPARK-27378,https://github.com/apache/spark/commit/0ced4c0b132334dac27de3ce45fd4cab8261cfb5,Add new code,[YARN] YARN support for GPU-aware scheduling,yarn.io/gpu yarn.io/fpga
SPARK-27453,https://github.com/apache/spark/commit/26ed65f4150db1fa37f8bfab24ac0873d2e42936,Add new code,Pass partitionBy as options in DataFrameWriter,spark.sql.legacy.sources.write.passPartitionByAsOptions
SPARK-27665,https://github.com/apache/spark/commit/8949bc7a3c1133bc17dac25111b222a788b826a8,Add new code,Split fetch shuffle blocks protocol from OpenBlocks,spark.shuffle.useOldFetchProtocol
SPARK-27677,https://github.com/apache/spark/commit/e9f3f62b2c0f521f3cc23fef381fc6754853ad4f,Add new code,Serve local disk persisted blocks by the external service after releasing executor by dynamic allocation,Constants.SHUFFLE_SERVICE_FETCH_RDD_ENABLED Constants.SHUFFLE_SERVICE_FETCH_RDD_ENABLED
SPARK-4502,https://github.com/apache/spark/commit/f2d35427eedeacceb6edb8a51974a7e8bbb94bc2,Add new code,Parquet nested column pruning - foundation,spark.sql.nestedSchemaPruning.enabled
SPARK-6951,https://github.com/apache/spark/commit/653fe02415a537299e15f92b56045569864b6183,Add new code,[CORE] Speed up parsing of event logs during listing.,spark.history.fs.inProgressOptimization.enabled spark.history.fs.endEventReparseChunkSize
SPARK-9104,https://github.com/apache/spark/commit/445f1790ade1c53cf7eee1f282395648e4d0992c,Add new code,[CORE] Expose Netty memory metrics in Spark,io.enableVerboseMetrics
SPARK-23850,https://github.com/apache/spark/commit/ed7ba7db8fa344ff182b72d23ae458e711f63432,Add new code,Add separate **CONFIG** for SQL options redaction,spark.sql.redaction.options.regex
SPARK-24324,https://github.com/apache/spark/commit/a5849ad9a3e5d41b5938faa7c592bcc6aec36044,Add new code,[PYTHON] Pandas Grouped Map UDF should assign result columns by name,spark.sql.execution.pandas.groupedMap.assignColumnsByPosition
SPARK-26103,https://github.com/apache/spark/commit/812ad5546148d2194ab0e4230ee85b8f6a5be2fb,Add new code,Limit the length of debug strings for query plans,spark.sql.debug.maxPlanLength
SPARK-28228,https://github.com/apache/spark/commit/1a26126d8c5e9bb647f858db236c370685f2f2d,Add new code,[SQL] Fix substitution order of nested WITH clauses,spark.sql.legacy.cte.substitution.enabled
SPARK-28209,https://github.com/apache/spark/commit/abef84a868e9e15f346eea315bbab0ec8ac8e38,Add new code,[CORE][SHUFFLE] Proposed new shuffle writer API,spark.shuffle.sort.io.plugin.class
SPARK-26329,https://github.com/apache/spark/commit/80ab19b9fd268adfc419457f12b99a5da7b6d1c,Add new code,[CORE] Faster polling of executor memory metrics.,spark.executor.metrics.pollingInterval
SPARK-28344,https://github.com/apache/spark/commit/6fb79af48c1bb93e7baf5a3d5646d86a95acc93,Add new code,[SQL] detect ambiguous self-join and fail the query,spark.sql.analyzer.failAmbiguousSelfJoin
SPARK-27371,https://github.com/apache/spark/commit/cbad616d4cb0c58993a88df14b5e30778c7f7e8,Add new code,[CORE] Support GPU-aware resources scheduling in Standalone,spark.resources.coordinate.enable spark.resources.dir
SPARK-25151,https://github.com/apache/spark/commit/594c9c5a3ece0e913949c7160bb4925e5d289e4,Add new code,[SS] Apply Apache Commons Pool to KafkaDataConsumer,spark.kafka.consumer.cache.jmx.enable spark.kafka.consumer.cache.timeout spark.kafka.consumer.cache.evictorThreadRunInterval spark.kafka.consumer.fetchedData.cache.timeout spark.kafka.consumer.fetchedData.cache.evictorThreadRunInterval
SPARK-11150,https://github.com/apache/spark/commit/a7a3935c97d1fe6060cae42bbc9229c087b648a,Add new code,[SQL] Dynamic Partition Pruning,spark.sql.optimizer.dynamicPartitionPruning.enabled spark.sql.optimizer.dynamicPartitionPruning.useStats spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcast
SPARK-21870,https://github.com/apache/spark/commit/cb0cddffe9452937033e0e6b1fc0e600d2c787a,Add new code,[SQL] Split aggregation code into small functions,spark.sql.codegen.aggregate.splitAggregateFunc.enabled
SPARK-29064,https://github.com/apache/spark/commit/bbfaadb280a80b511a98d18881641c6d9851dd5,Add new code,[CORE] Add PrometheusResource to export Executor metrics,spark.ui.prometheus.enabled
SPARK-28997,https://github.com/apache/spark/commit/a1213d5f963f6e8815bbfaff308b0a24112fff5,Add new code,[SQL] Add `spark.sql.dialect`,spark.sql.dialect
SPARK-29783,https://github.com/apache/spark/commit/5cebe587c7132fa6ea502084d45e0d8b203481b,Add new code,[SQL] Support SQL Standard/ISO_8601 output style for interval type,spark.sql.intervalOutputStyle
SPARK-28560,https://github.com/apache/spark/commit/9ac4b2dbc55a1114fea313483e5543d83c35221,Add new code,[SQL] Optimize shuffle reader to local shuffle reader when smj converted to bhj in adaptive execution,spark.sql.adaptive.optimizedLocalShuffleReader.enabled
SPARK-28869,https://github.com/apache/spark/commit/100fc58da54e026cda87832a10e2d06eaeccdf8,Add new code,[CORE] Roll over event log files,"spark.eventLog.rollLog, spark.eventLog.rollLog.maxFileSize"
SPARK-29397,https://github.com/apache/spark/commit/d51d228048d519a9a666f48dc532625de13e758,Add new code,[CORE] Extend plugin interface to include the driverSpark 2.4 added the ability for executor plugins to be loaded intoSpark (see SPARK-24918).,spark.plugins
SPARK-20568,https://github.com/apache/spark/commit/ba2bc4b0e0eea0c1b6732a18cb20e61e4f69315,Add new code,[SS] Provide **OPTION** to clean up completed files in streaming query,cleanSource (API configuration)
SPARK-24768,https://github.com/apache/spark/commit/395860a986987886df6d60fd9b26afd818b2cb39#,Add new code,Have a built-in AVRO data source implementation,spark.sql.avro.deflate.level
SPARK-27990,https://github.com/apache/spark/commit/3dd3a623f293bc7fd4937c95f06b967fa187b0f,Add new code,[SPARK-29903][PYTHON] Add recursiveFileLookup **OPTION** to Python DataFrameReader,recursiveFileLookup (API configuration)
SPARK-27189,https://github.com/apache/spark/commit/729f43f499f3dd2718c0b28d73f2ca29cc811ea,Add new code,[CORE] Add Executor metrics and memory usage instrumentation to the metrics system,spark.metrics.executorMetricsSource.enabled
SPARK-29864,https://github.com/apache/spark/commit/e933539cdd557297daf97ff5e532a3f09889697,Add new code,[SPARK-29920][SQL] Strict parsing of day-time strings to intervals,spark.sql.legacy.fromDayTimeString.enabled
SPARK-30240,https://github.com/apache/spark/commit/a9fbd310300e57ed58818d7347f3c3172701c49,Add new code,[CORE] Support HTTP redirects directly to a proxy server,spark.ui.proxyRedirectUri
SPARK-29938,https://github.com/apache/spark/commit/07b04c4c72ef0a1c6631afc2dc6d9be9817e319,Add new code,[SQL] Add batching support in Alter table add partition flow,spark.rdd.parallelListingThreshold
SPARK-21869,https://github.com/apache/spark/commit/7bff2db9ed803e05a43c2d875c1dea819d81248,Add new code,[SS] Revise Kafka producer pool to implement 'expire' correctly,spark.kafka.producer.cache.evictorThreadRunInterval
SPARK-29001,https://github.com/apache/spark/commit/0346afa8fc348aa1b3f5110df747a64e3b2da38,Add new code,[CORE] Print events that take too long time to process,"spark.scheduler.listenerbus.logSlowEvent.enabled, spark.scheduler.listenerbus.logSlowEvent.threshold"
CASSANDRA-11097,https://github.com/apache/cassandra/commit/0240a4659d761f06f94f8cd97097f2d0ad2d220c,Add code change,Introduce optional timeouts for idle client sessions,native_transport_idle_timeout_in_ms
CASSANDRA-13884,https://github.com/apache/cassandra/commit/c22ee2bd451d030e99cfb65be839bbc735a5352f,Add code change,Add sstableloader **OPTION** to accept target keyspace name,TARGET_KEYSPACE
CASSANDRA-13987,https://github.com/apache/cassandra/commit/05cb556f90dbd1929a180254809e05620265419b,Add code change,More frequent commitlog chained markers,commitlog_marker_period_in_ms
CASSANDRA-12014,https://github.com/apache/cassandra/commit/ae88fd6c79b066f12ad76c2c1bfc1620d86bdbc5,Add code change,Avoid assertion error when IndexSummary > 2G,index_summary_expected_key_size
CASSANDRA-13651,https://github.com/apache/cassandra/commit/96ef514917e5a4829dbe864104dbc08a7d0e0cec,Add code change,Remove Netty timed batching and instead do the batch during next eventLoop invocation after a write has been enqueued. ,native_transport_flush_in_batches_legacy
CASSANDRA-14275,https://github.com/apache/cassandra/commit/19d26bcb80219bce0089fbe8942a34e3a331fd17,Add code change,Add ability to specify driver name and version,DRIVER_NAME DRIVER_VERSION
CASSANDRA-15002,https://github.com/apache/cassandra/commit/7f634feb7cf1fdb135133946ffd75efa681b8cb7,Add code change,Avoid leaking threads when remote nodes fail anticompaction and rate limit anticompactions,cassandra.acquire_sleep_ms cassandra.acquire_retry_seconds
CASSANDRA-15193,https://github.com/apache/cassandra/commit/0388d89e29393d0b1f50baa24848bc8cb0a7c9a3,Add code change,Allow max protocol version to be cappedPatch,disable_max_protocol_auto_override
CASSANDRA-12151,https://github.com/apache/cassandra/commit/f56871b88be1e8965f166769c12cfa43313bac74,Add new code,Audit logging for database activity,audit_logging_options
CASSANDRA-13006,https://github.com/apache/cassandra/commit/02aba7343ce300397ab672bbb1788aa8182d8a48,Add new code,Rely on the JVM to handle OutOfMemoryErrors,cassandra.printHeapHistogramOnOutOfMemoryError
CASSANDRA-13299,https://github.com/apache/cassandra/commit/8ef71f3f29fb040cce18ba158ff5f289b388c30b,Add new code,Throttle base partitions during MV repair streaming to prevent OOM,cassandra.repair.mutation_repair_rows_per_batch
CASSANDRA-13897,https://github.com/apache/cassandra/commit/5b23054f10f4d6553e8dacbf53bd59e552f2a031,Add new code,Round buffer size to powers of 2 for the chunk cache,file_cache_round_up
CASSANDRA-13975,https://github.com/apache/cassandra/commit/f1e850a492126572efc636a6838cff90333806b9,Add new code,Add flag to allow dropping oversized read repair mutations,cassandra.drop_oversized_readrepair_mutations
CASSANDRA-13983,https://github.com/apache/cassandra/commit/ae837806bd07dbb8b881960feeeeb90c1a665d93,Add new code,Support a means of logging all queries as they were invoked.,full_query_log_dir
CASSANDRA-13985,https://github.com/apache/cassandra/commit/54de771e643e9cc64d1f5dd28b5de8a9a91a219e,Add new code,Add network auth,network_authorizer
CASSANDRA-13993,https://github.com/apache/cassandra/commit/b86801e95a58c5f1a9c779b21fa57136e0225d61,Add new code,Add optional startup delay to wait until peers are ready,block_for_peers_percentage block_for_peers_timeout_in_secs
CASSANDRA-14092,https://github.com/apache/cassandra/commit/b2949439ec62077128103540e42570238520f4ee,Add new code,Protect against overflow of local expiration time,cassandra.expiration_overflow_warning_interval_minutes
CASSANDRA-14145,https://github.com/apache/cassandra/commit/5fbb938adaafd91e7bea1672f09a03c7ac5b9b9d,Add new code,Detect inconsistencies in repaired data on the read path,repaired_data_tracking_for_range_reads_enabled repaired_data_tracking_for_partition_reads_enabled report_unconfirmed_repaired_data_mismatches
CASSANDRA-14197,https://github.com/apache/cassandra/commit/d14a9266c7ddff0589fdbe7a1836217b8bb8b394,Add new code,Automatic sstable upgrades,automatic_sstable_upgrade max_concurrent_automatic_sstable_upgrades
CASSANDRA-14373,https://github.com/apache/cassandra/commit/6e00ab956eb0148a74e926666862e4cc78936301,Add new code,Allow using custom script for chronicle queue BinLog archival,full_query_logging_options
CASSANDRA-14467,https://github.com/apache/cassandra/commit/5d8767765090cd968c39008f76b0cd795d6e5032,Add new code,Add option to sanity check tombstones on reads/compaction,corrupted_tombstone_strategy
CASSANDRA-14566,https://github.com/apache/cassandra/commit/47a12c52a313258307ab88392f75c5866d9a2bb1,Add new code,Stream entire SSTables when possible,stream_entire_sstables
CASSANDRA-14821,https://github.com/apache/cassandra/commit/f22fec927de7ac291266660c2f34de5b8cc1c695,Add new code,Introduce in-jvm distributed tests,org.apache.cassandra.disable_mbean_registration
CASSANDRA-14855,https://github.com/apache/cassandra/commit/fff6eec2903ee85f648535dd051c9bc72631f524,Add new code,Backport ImmediateFlusher to cassandra-3.0 and cassandra-3.11,native_transport_flush_in_batches_legacy
CASSANDRA-14866,https://github.com/apache/cassandra/commit/e6a61be8c857106d5d99a270b2d17de9f84c4d67,Add new code,"Add flag to disable SASI indexes, and warning on creation",enable_sasi_indexes
CASSANDRA-15059,https://github.com/apache/cassandra/commit/c3ce32e239b1ba41faf1d58a942465b9bf45b986,Add new code,Fix assorted gossip races and add related runtime checks,cassandra.strict.runtime.checks cassandra.gossip.disable_thread_validation
CASSANDRA-15202,https://github.com/apache/cassandra/commit/2117e2af00603f5fb2181e53dbcba190b2eab861,Add new code,Make repair coordination less expensive by moving MerkleTrees off heap,use_offheap_merkle_trees
CASSANDRA-3200,https://github.com/apache/cassandra/commit/cb56d9fc3c773abbefa2044ce41ddbfb7717e0cb,Add new code,Add option to optimize Merkle tree comparison across replicas,optimiseStreams
CASSANDRA-13594,https://github.com/apache/cassandra/commit/62d39f6544e3fbcbc268aecbb3a46950dcba2bf0,Add new code,Use an ExecutorService for repair commands instead of new Thread(..).start(),repair_command_pool_size repair_command_pool_full_strategy
CASSANDRA-15013,https://github.com/apache/cassandra/commit/5a03898c680ed6ada63901e8a4b278ccc8070717,Add new code,Prevent client requests from blocking on executor task queue,native_transport_max_concurrent_requests_in_bytes_per_ip native_transport_max_concurrent_requests_in_bytes
CASSANDRA-14404,https://github.com/apache/cassandra/commit/f7431b432875e334170ccdb19934d05545d2cebd,Add new code,Transient Replication and Cheap Quorums,enable_transient_replication